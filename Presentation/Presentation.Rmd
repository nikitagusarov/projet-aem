---
title: "Etude des effets des pésticides dans la production des vins de table"
shorttitle : "Les effets des pésticides"
subtitle: "Analyse empirique des marchés"
author: A. Blanc, N. Gusarov, S. Picon
shortauthor : A.Blanc, N.Gusarov, S.Picon
institute: Université Grenoble Alpes
shortinstitute: UGA
date: 19/12/2019
header-includes:
    - \usepackage{array}
    - \usepackage{multicol}
output: 
    beamer_presentation:
        theme: "Montpellier"
        colortheme: "beaver"
        # template: Template.tex
        slide_level: 2
        # fonttheme: "structurebold"
        toc: FALSE
        # toc_depth: 1
        df_print: "kable"
        fig_width: 4
        fig_height: 2.8
        fig_caption: yes
        includes:
            in_header: Header.tex
fontsize: 11pt
# geometry: margin = 0.5in
---

```{r include = FALSE}
###################
# Setting r options
###################
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(size = "tiny")
knitr::opts_chunk$set(dpi = 600)
knitr::opts_chunk$set(fig.align = "center") 
knitr::opts_chunk$set(fig.pos = "!htbp")
# Set chunk size
def.chunk.hook  = knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = 
    function(x, options) {
        x = def.chunk.hook(x, options)
        ifelse(options$size != "normalsize", 
            paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
    })
```

```{r include = FALSE, eval = FALSE}
# Extract R code from Rmd
require(knitr)
purl("./Presentation/Presentation.Rmd", 
    output = "./Presentation/CodePresentation.R", 
    documentation = 0)
```

```{r include = FALSE}
##########
# Packages
##########
# DAta management
require(tidyverse)
require(rlang)
require(dummies)
# Modelisation
require(plm)
require(Formula)
require(systemfit)
require(olsrr)
# Graphics
require(gridExtra)
# Print latex results
require(stargazer)
require(texreg)
require(xtable)
```

```{r include = FALSE}
##############
# Loading data
##############
# Data
data = read.csv("../Donnees/Base-de-donnees-indice-prix.csv")
# names(data)
# Arrange
dn = data %>%
    filter(s_vin_simple != 0 & 
        (q_rouge + q_blanc) != 0 &
        (qk_prod + ql_prod) != 0 &
        IP != 0) %>%
    na.omit() %>%
    group_by(ndep) %>%
    count() %>% 
    filter(n == 5) # %>%
    # select(ndep)
datax = data %>% 
    filter(ndep %in% dn$ndep) 
datay = datax %>% 
    filter(annee == 2012) %>%
    mutate(refqki = qk_prod + ql_prod) %>% 
    select(ndep, refqki) 
datax = left_join(datax, datay)
datax = datax %>%
    mutate(IQK = (qk_prod + ql_prod)/refqki)
```

```{r include = FALSE}
##################
# Transformed data
##################
datai = datax %>%
    arrange(ndep) %>%
    mutate(si = log(s_vin_simple + 0.001), 
        qi = log(q_blanc + q_rouge + 0.001), 
        ipi = IP,
        ri = log(revenu.déflaté),
        iki = IQK,
        t = as.integer(as.factor(annee)),
        year = annee) %>%
    dplyr::select(year, ndep, qi, ipi, si, ri, iki, t)
```

```{r include = FALSE}
############
# Panel data
############
datap = pdata.frame(datai, index = c("ndep", "year"),
    drop.index = T)
```

```{r include = FALSE}
#################
# Clear workplace
#################
list = ls()
keep = c("datai", "datap")
omit = setdiff(list, keep)
rm(omit)
```

```{r include = FALSE}
###################
# Support functions
###################
# xtsum (overall, within and between variance) for panel data
# STATA version
xtsum = function(data, varname, unit) {
    # the variable to xtsum over
    varname = enquo(varname)
    # the identifier dimention
    loc.unit = enquo(unit)
    # overall
    ores = data %>% 
        summarise(ovr.mean = mean(!! varname, na.rm = TRUE), 
        ovr.sd = sd(!! varname, na.rm = TRUE), 
        ovr.min = min(!! varname, na.rm = TRUE), 
        ovr.max = max(!! varname, na.rm = TRUE), 
        ovr.N = sum(as.numeric((!is.na(!! varname)))))
    # between
    bmeans = data %>% 
        group_by(!! loc.unit) %>% 
        summarise(meanx = mean(!! varname, na.rm = TRUE), 
        t.count = sum(as.numeric(!is.na(!! varname))))
    bres = bmeans %>% 
        ungroup() %>% 
        summarise(between.sd = sd(meanx, na.rm = TRUE), 
        between.min = min(meanx, na.rm = TRUE), 
        between.max = max(meanx, na.rm = TRUE), 
        units = sum(as.numeric(!is.na(t.count))), 
        t.bar = mean(t.count, na.rm = TRUE))
    # within
    wdat = data %>% 
        group_by(!! loc.unit) %>% 
        mutate(W.x = scale(!! varname, scale = FALSE))
    wres = wdat %>% 
        ungroup() %>%  
        summarise(within.sd = sd(W.x, na.rm = TRUE), 
        within.min = min(W.x, na.rm = TRUE), 
        within.max = max(W.x, na.rm = TRUE))
    # results
    return(list(var = varname, ores = ores, bres = bres, wres = wres))
}
# Print results for a list of xtsums
print.xtsum = function(xtsums.list) {
    # takes multiple xtsums as list
    df = data.frame(Variable = NA, Mean = NA,
        Overall = NA, Between = NA, Within = NA)
    # Filling loop
    for (i in 1:length(xtsums.list)) {
        df[i,1] = as_name(xtsums.list[[i]]$var)
        df[i,2] = xtsums.list[[i]]$ores$ovr.mean 
        df[i,3] = xtsums.list[[i]]$ores$ovr.sd
        df[i,4] = xtsums.list[[i]]$bres$between.sd
        df[i,5] = xtsums.list[[i]]$wres$within.sd
    }
    # Rownames
    rownames(df) = df[,1]
    # Results
    return(df = df[,-1])
}
```

```{r include = FALSE}
##################
# Set ggplot style
##################
pres_theme = theme(text = element_text(size = rel(3)),
    legend.position = "none")
```

```{r include = FALSE}
#################
# Effects testing 
#################
Effect.testing = function(Formulas, data) {
    Dtest = data.frame(var = 0,
        Random = 0, Fixed = 0, 
        Individual = 0, Time = 0, Twoways = 0)
        for (i in 1:length(Formulas)) {
            Dtest[i,1] = names(Formulas)[i]
            ## Chow test
            # Random coefs for random effects          
            Dtest[i,2] = pooltest(Formulas[[i]],
                data = data,
                model = "random")$p.val 
            # Different coefs for fixed effects
            Dtest[i,3] = pooltest(Formulas[[i]],
                data = data,
                model = "within")$p.val
            ## Lagrange multiplier tests
            # Individual effects
            Dtest[i,4] = plmtest(Formulas[[i]],
                data = data,
                effect = "individual",
                type = "bp")$p.val
            # Time effects
            Dtest[i,5] = plmtest(Formulas[[i]],
                data = data,
                effect = "time",
                type = "bp")$p.val
            # Two-ways effects (individual and time)
            Dtest[i,6] = plmtest(Formulas[[i]],
                data = data,
                effect = "twoways",
                type = "ghm")$p.val   
        }
    rownames(Dtest) = Dtest[,1]
    return(Dtest = Dtest[,-1])
}
```

# Introduction
```{r eval = FALSE, include = FALSE}
####################################################
################### Introduction ###################
####################################################
```

## Introduction
\center
\textbf{Quel est l'effet de l'utilisation des pesticides sur le marché des vins simples ?}

Dans cette étude, nous chercherons à étudier l'équilibre sur le marché du vin. 

## Plan de la présentation
- Présentation de la problématique
    - Pesticides 
    - Marché du vin 

- Le modèle théorique 
- Les données
- Modélisation
- Les résultats
- Conclusion 

# Les pesticides
```{r eval = FALSE, include = FALSE}
####################################################
###################  Pesticides  ###################
####################################################
```

## Les pesticides
- Présentation du problème des pésticides
- Etat actuel
- Comment baisser l'utilisation de pesticides

## Présentation du problème des pesticides
- Source de nombreux débats sur la santé et l'environnement.
- Le rôle actuel :
    - Moyen de protection contre les aléas climatiques ;
    - Outil pour la réservation du rendement.

- Plusieurs mesures mises en places pour réduire leurs usages :
    - des interdiction des produits les plus toxiques ;
    - l'instauration d'une taxe, payée par les agriculteurs (Butault et al, 2011).

- Malgres les efforts l'utilisation perdure :
    - Hausse des ventes de produits phytosanitaires ;
    - Augmentation des doses utilisés (+12% en 2014-2016) ;
  
## Etat actuel
Contrairement aux attentes des autorités aucune baisse de l'utilisation de pesticides :

- Le nombre de doses unité augmente de 23% entre 2008 et 2017 ;
- Le nombre de substances actives utilisées a augmenté de 15% entre 2011 et 2017 ;
- Une baisse des produits les plus dangereux de 6%, en 2017 (Moghaddam et al, 2019) ;
- Les grandes cultures (blés, etc...) sont les premières utilisatrices de pesticides 67.4% ;
- Les vignes sont les deuxièmes 14.4% (Butault et al, 2011).
    
## Comment baisser l'utilisation de pesticides
Les méthodes contemporaines visant à baisser l'utilisation des pésticides sont :

- Le changement de mode de culture :
    - agriculture biologique ;
    - agriculture raisonnée ;
- La diversification des cultures, ce qui est impossible pour la vigne (Moghaddam et al, 2019).

# Le marché du vin français
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Viticulture  ###################
#####################################################
```

## Le marché du vin français
- Le vin français 
- Utilisation des pésticides dans la viticulture
- Le problème d'heterogénéité
- Les vins de table
- Le marché des vins de table français

## Le vin français 
France est un producteur de vin important :

- 10% surface de vigne mondiale ;
- 3% de la surface agricole française est dediée au vin ;
- 16% de la production mondiale ;
- Le vin est la boisson alcoolisée la plus consommée en France ;
- 88% des ventes de vins en France sont effectuées dans des grandes surfaces (CNIV, 2018).

La consommation de vins en France, tous types (FranceAgrimer, 2011) :

- 55% de vins rouges ;
- 16% de vins blancs ;
- 29% de vins rosés.
  
## Utilisation des pesticides dans la viticulture
La viticulture un type de culture gourmand en pesticides :

- 14.4% des produits phytosanitaires utilisés en France ;
- 2-ème culture utilisatrice de pesticides en France ;
- Fortes disparités d'utilisation des pesticides entre les régions (Butault et al, 2011) ;
- Les bassins viticoles Français utilisent en majorité des fongicides et des bactéricides sur la vigne ;
- La champagne est la région la plus utilisatrice de pesticide avec un IFT de 21.4 en 2013 ;
  
## Le problème d'heterogénéité
Il existe une forte hétérogénéité entre les différents labels mais aussi à l'intérieur de ces labels. 

Les vins peuvent être divisés en 2 grandes classes suivant leurs prix (Cembalo et al., 2014) :

- Les vins de qualité supérieure
    - limitation des quantités produites
    - l'origine contrôlé 
    - une demande spécifique

- Les vins de qualité faible
    - hétérogènéité moins importante (Cembalo et al., 2014)

## Les vins de table
Les vins de tables sont des vins sans indication géographiques :

- hétérogènéité plus faible que pour les autre types ;
- prix bas.

Nous traitons seulement des vins sans indication géographique :

- La situation sur ce marché influence l'utilisation des pesticides ;
- Il existe une homogénéité presque parfaite dans les vins sans indication géographique (Cembalo et al, 2014).

## Le marché des vins de tables Français
Représente 10% de la production (VIN & SOCIETE, 2018)

- Hausse des transactions en 2011 :
    - Vins rouges : 29 %
    - Vins rosés : 13% 
    - Vins blancs : 76%

- Hausse des prix en 2011 : 
    - Vins rouges : 12%
    - Vins rosés : 3%
    - Vins blancs : 13%

# Le Modèle théorique
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Théorie mod  ###################
#####################################################
```

## Le Modèle théorique
- Le rôle des pesticides dans la production du vin
- Le rôle de la demande sur la production et l'offre en général
- La formalisation et les équations

## Le rôle de la demande sur la production et l'offre en génèral
- Nous supposons que sur le marché des vins simples la demande est unique pour toute la France.
- La production de vin varie par département à cause de variations climatologiques
- On observe l'équilibre sur le marché au niveau du pays. Ainsi, la quantité demandée = quantité offerte par l'ensemble des régions.
- La demande de pesticides est inélastique au prix. Ainsi, la quantité de pesticides utilisée dépend seulement des intentions et des besoins des agriculteurs.

# Les données
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Données mob  ###################
#####################################################
```

## Les données
- Souces des données 
- Déscription des données 
- Les variables choisi
- Les variables utilisées pour notre modèle

## Sources des données : 
- Les données de ventes de pesticides par département (INERIS)
- Les données sur les prix du vin (FranceAgrimer)
- Les données sur la population (INSEE)
- Les données sur la production de vin (SSM Finances Publiques)
- Variation par département français (pour les régions produisant le vin)
- Variation par année (2012 à 2016)
   
## Déscription des données :
- Toutes les variables varient par département et par année.
- Le période temporelle comprise dans notre échantillon est de 2012 à 2016.
- Sélection des régions productrices de vin et utilisatrices de pesticides (69 départements).
- Utilisation de l'echelle logarithmique afin de contracter la variance.

## Les variables utilisées pour notre modèle
- Variables endogènes : 
    - la quantité totale produite de vin rouge et blanc non IG par département (en hectolitres, en log), 
    - le prix moyen des vins rouges-blancs (idice, en log).
- Variables exogènes : 
    - le revenu médian par département (en euros par personne par année, en log), 
    - la surface agricole destinée aux vins de table (en hectares, en log),
    - la quantité des pesticides utilisés sur la vigne (indice, en log).

# L'étude statistique
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Statistique  ###################
#####################################################
```

## L'étude statistique 
- L'étude bivarié
- L'étude de la variance 
- L'étude des types d'effets
- L'analyse de la correlation
- La transformation **within**

## Visualisatoin des interdependances
```{r echo = FALSE}
p1 = datai %>% 
    ggplot(aes(qi, ipi, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ IP") +
    xlab("Quantité du vin") + ylab("Index du prix") +
    pres_theme
p2 = datai %>% 
    ggplot(aes(qi, iki, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ IK") +
    xlab("Quantité du vin") + ylab("Index des pésticides") +
    pres_theme
grid.arrange(p1, p2, nrow = 1)
# Probably it is better to do it by variable
```

## Visualisatoin des interdependances
```{r echo = FALSE}
p1 = datai %>% 
    ggplot(aes(qi, si, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ S") +
    xlab("Quantité du vin") + ylab("Surface qultivé") +
    pres_theme
p2 = datai %>% 
    ggplot(aes(qi, ri, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ R") +
    xlab("Quantité du vin") + ylab("Revenus") +
    pres_theme
grid.arrange(p1, p2, nrow = 1)
```

## Etude de la variance 
```{r include = FALSE}
lxtsums = list()
# list
lxtsums[[1]] = xtsum(datai, ipi, ndep)
lxtsums[[2]] = xtsum(datai, iki, ndep)
lxtsums[[3]] = xtsum(datai, si, ndep)
lxtsums[[4]] = xtsum(datai, ri, ndep)
lxtsums[[5]] = xtsum(datai, t, ndep)
# results
results = print.xtsum(lxtsums)
rownames(results) = c("Index prix", "Index pesticides",
    "Surface", "Revenus", "Temps")
```


```{r echo = FALSE, results = "asis"}
stargazer(results, 
    header = FALSE,
    title = "Variance par type",
    summary = FALSE)
```


```{r include = FALSE}
Formulas = list(
    ipi = qi ~ ipi,
    iki = qi ~ iki,
    si = qi ~ si,
    ri = qi ~ ri)
Dtest = Effect.testing(Formulas, data = datap)
rownames(Dtest) = c("Index prix", "Index pesticides",
    "Surface", "Revenus")
```


```{r echo = FALSE, results = "asis"}
stargazer(Dtest[,c(1:2)], 
    header = FALSE,
    title = "Chow pooling test",
    summary = FALSE)
```


## L'étude des types d'effets 


```{r echo = FALSE, results = "asis"}
stargazer(Dtest[,c(3:ncol(Dtest))], 
    header = FALSE,
    title = "Lagrange multiplier test, p-values",
    summary = FALSE)
```


## L'analyse de la correlation

```{r echo = FALSE}
correlation = cor(datap)
colnames(correlation) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
rownames(correlation) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
```


```{r echo = FALSE, results = "asis"}
xtable(round(correlation, 4), 
    caption = "Overall correlation",
    align = "l|cccccc")
```


```{r include = FALSE}
###################
# Rework the matrix WITHIN_TRANSFORM
###################
rm(datax) ; rm(datay) ; rm(data) ; rm(dn)
dataW = datap 
dataW$qi = Within(datap$qi)
dataW$ipi = Within(datap$ipi)
dataW$iki = Within(datap$iki)
dataW$si = Within(datap$si)
dataW$ri = Within(datap$ri)
```

```{r include = FALSE}
correlationW = cor(dataW)
dataW$ndep = index(datap)$ndep
colnames(correlationW) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
rownames(correlationW) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
```


```{r echo = FALSE, results = "asis"}
xtable(round(correlationW, 4), 
    caption = "Within transformation correlation",
    align = "l|rrrrrr")
```


## La transformation **within**


```{r echo = FALSE}
p1 = dataW %>% 
    ggplot(aes(qi, ipi, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, ipi, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ IP") +
    xlab("Quantité du vin") + ylab("Index du prix") +
    pres_theme
p2 = dataW %>% 
    ggplot(aes(qi, iki, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, iki, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ IK") +
    xlab("Quantité du vin") + ylab("Index des pésticides") +
    pres_theme
grid.arrange(p1, p2, nrow = 1)
# Probably it is better to do it by variable
```


## La transformation **within**


```{r echo = FALSE}
p1 = dataW %>% 
    ggplot(aes(qi, si, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, si, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ S") +
    xlab("Quantité du vin") + ylab("Surface qultivé") +
    pres_theme
p2 = dataW %>% 
    ggplot(aes(qi, ri, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, ri, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ R") +
    xlab("Quantité du vin") + ylab("Revenus") +
    pres_theme
grid.arrange(p1, p2, nrow = 1)
```


# Modèlisation
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Modèlisation  ##################
#####################################################
```

## Modèlisation
- Presentation de la méthode 
- Les estimations 
    - OLS
    - 2SLS, W2SLS, 3SLS et i3SLS 

## Presentation de la méthode
- Explication de la méthode utilisée
    - Panel data
        - Within transforation 
        - Fixed effects 
        - Obtained slopes are averages for all population 
    - AIDS model 
        - Interdependent equations (simultaneity bias)
        - 3SLS estimator (that is identical to ILS estimator)
        - It generates consistent estimates
        - The distribution of the estimators are normally distributed only in large samples 
        - The estimator is (asymptotically) efficient
- Limites du modèle 
    - Faible representation des effets hetérogenes entre les régions (nous estimons seulemnt les effets moyens)
    - Les interferences induites par l'heterogénéité 

```{r include = FALSE, eval = FALSE}
###################
# Not evaluated !!!
###################
###################
# Rework the matrix DUMMIES
###################
Dum = dummy(datai$ndep, sep = "_")
# Index pésticides
IKI = as.matrix(datai$iki)[, rep(1, each = length(unique(datai$ndep)))]
ikiDum = as.data.frame(Dum*IKI) %>% 
    setNames(paste0('iki_', names(.)))
rm(IKI)
# Revenus
RI = as.matrix(datai$ri)[, rep(1, each = length(unique(datai$ndep)))]
riDum = as.data.frame(Dum*RI) %>% 
    setNames(paste0('ri_', names(.)))
rm(RI)
# Concatenate
dataD = datai %>% 
    select(-c(t, ri, iki)) %>% 
    cbind(Dum) %>% 
    cbind(ikiDum) %>% 
    cbind(riDum)
```

```{r include = FALSE, eval = FALSE}
###################
# Not evaluated !!!
###################
###################
# Rework the matrix WITHINxDUMMIES
###################
Dum = dummy(datai$ndep, sep = "_")
# Index pésticides
IKI = as.data.frame(dataW$iki, ncol = 1)[, rep(1, each = length(unique(datai$ndep)))]
ikiDum = as.data.frame(Dum*IKI)
ikiDum = ikiDum %>%
    set_names(~str_replace_all(., "dataW\\$", ""))
rm(IKI)
# Revenus
RI = as.data.frame(dataW$ri)[, rep(1, each = length(unique(datai$ndep)))]
riDum = as.data.frame(Dum*RI) %>%
    rename_all(list(~str_replace_all(., "dataW\\$", "")))
rm(RI)
# Concatenate
dataWD = dataW %>% 
    select(-c(t, ri, iki)) %>% 
    cbind(ikiDum) %>% 
    cbind(riDum)
rm(ikiDum) ; rm(riDum)
```

## Résultats des estimation
- Les coefficients estimés avec leurs variance 
- L'efficience et comparaison des estimateurs 
- Etude des erreurs 
    - La distribution des erreurs
        - La normalité 
        - Centrage sur 0 
        - Independance des variables explicatives 

    - L'autocorrelation des résidus 
    - L'hétéroskedacité  

```{r include = FALSE, eval = FALSE}
# - Vérification des hypothèses (5 hypothèses) :
#     - La moyenne nulle des erreurs 
#     - La normalité des residus 
#     - Homoscedacité 
#     - Autocorrélation 
#     - Spécification du modèle
# 3SLS and FIML are asymptotically equivalent. 
# Hence 3SLS is efficient and FIML is consistent even if residuals are not normal.
```

## Les résultats OLS

```{r include = FALSE}
# Data transformation for systemfit
dataWX = as.data.frame(dataW)
```

```{r include = FALSE}
# equations
eqdemand = qi ~ 0 + ipi + ri
eqoffer = qi ~ 0 + ipi + si + iki 
system = list(Demande = eqdemand, Offre = eqoffer)
# OLS
ols = lm(eqoffer, 
    data = dataWX, 
    method = "OLS")
# # WLS
# wls = systemfit(system, 
#     data = dataWX, 
#     method = "WLS")
# # SUR
# sur = systemfit(system, 
#     data = dataWX, 
#     method = "SUR")
```


```{r echo = FALSE, results = "asis"}
texreg(list(ols #, wls, sur
        ),
    custom.model.names = c("OLS" #, "WLS", "SUR"
        ),
    label = "table : ols" #, wls and sur"
        )
```


## Independance des résidus   
```{r include = FALSE}
cordata = dataWX %>% 
    mutate(u1 = ols$res
        # u1 = ols$eq[[1]]$res,
        # u2 = ols$eq[[2]]$res,
        # u3 = wls$eq[[1]]$res,
        # u4 = wls$eq[[2]]$res,
        # u5 = sur$eq[[1]]$res,
        # u6 = sur$eq[[2]]$res
        )
cormat = cor(cordata[,-c(6,7)])[1:5, 6] %>% 
    as.data.frame()
colnames(cormat) = c("OLS" # D", "OLS O", 
#         "WLS D", "WLS O", 
#         "SUR D", "SUR O"
        )
rownames(cormat) = c("Vin", "IP", 
        "Surface", "Revenus", 
        "Pesticides")
```


```{r echo = FALSE, results = "asis"}
xtable(round(cormat, 4),
    caption = "Correlation des résidus",
    align = "l|r" #rrrr"
    )
# cordata %>% ggplot(aes(x = u6, y = f6)) + geom_point() + geom_smooth()
```


## Test
```{r include = FALSE}
# Panel Durbin-Watson test
cordataDW = cordata %>% 
    group_by(ndep) %>%
    mutate(u1_diff = u1 - dplyr::lag(u1),
        # u2_diff = u2 - dplyr::lag(u2),
        # u3_diff = u3 - dplyr::lag(u3),
        # u4_diff = u4 - dplyr::lag(u4),
        # u5_diff = u5 - dplyr::lag(u5),
        # u6_diff = u6 - dplyr::lag(u6)
        ) %>%
    ungroup() %>%
    select(contains("u")) %>%
    mutate_all(function(x) replace_na(x, 0)) %>%
    summarise_all(function(x) sum(x^2))
pDW = data.frame(ncol = 1, nrow = 1)#(ncol = 3, nrow = 2)
pDW[1,1] = cordataDW[1,1]/cordataDW[1,2]
# pDW[2,1] = cordataDW[1,2]/cordataDW[1,8]
# pDW[1,2] = cordataDW[1,3]/cordataDW[1,9]
# pDW[2,2] = cordataDW[1,4]/cordataDW[1,10]
# pDW[1,3] = cordataDW[1,5]/cordataDW[1,11]
# pDW[2,3] = cordataDW[1,6]/cordataDW[1,12]
colnames(pDW) = c("OLS" #, "WLS", "SUR"
    )
rownames(pDW) = c( #"Equation de demande", 
    "Equation d'offre")
```


```{r echo = FALSE, results = "asis"}
stargazer(pDW, 
    header = FALSE,
    title = "Durbin-Watson test statistics",
    summary = F)
```


```{r echo = FALSE, results = "asis"}
BartT = data.frame(ncol = 1, nrow = 1)
#    (ncol = 3, nrow = 2)
BartT[1,1] = ols_test_bartlett(cordata, u1, 
    group_var = ndep)$pval 
# BartT[2,1] = ols_test_bartlett(cordata, u2, 
#     group_var = ndep)$pval
# BartT[1,2] = ols_test_bartlett(cordata, u3, 
#     group_var = ndep)$pval
# BartT[2,2] = ols_test_bartlett(cordata, u4, 
#     group_var = ndep)$pval
# BartT[1,3] = ols_test_bartlett(cordata, u5, 
#     group_var = ndep)$pval
# BartT[2,3] = ols_test_bartlett(cordata, u6, 
#     group_var = ndep)$pval
colnames(BartT) = c("OLS" #, "WLS", "SUR"
    )
rownames(BartT) = c(#"Equation de demande", 
    "Equation d'offre")
```


```{r echo = FALSE, results = "asis"}
stargazer(BartT,
    header = FALSE,
    summary = FALSE,
    title = "Bartlett heteroscedasticity test")
```

```{r include = FALSE}
ShapT = data.frame(nrow = 2, ncol = 6)
ShapT[1,1] = shapiro.test(ols$res)$p.val
# ShapT[1,1] = shapiro.test(ols$eq[[1]]$res)$p.val
# ShapT[2,1] = shapiro.test(ols$eq[[2]]$res)$p.val
# ShapT[1,2] = shapiro.test(wls$eq[[1]]$res)$p.val
# ShapT[2,2] = shapiro.test(wls$eq[[2]]$res)$p.val
# ShapT[1,3] = shapiro.test(sur$eq[[1]]$res)$p.val
# ShapT[2,3] = shapiro.test(sur$eq[[2]]$res)$p.val
colnames(ShapT) = c("OLS" #, "WLS", "SUR"
    )
rownames(ShapT) = c(#"Equation de demande", 
    "Equation d'offre")
```

```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk normality test")
```


## Présentation graphique des résidus 
```{r echo = FALSE}
par(mfrow = c(1,2), cex = 0.5)
# par(mfrow = c(1,2), cex = 0.5)
plot(density(ols$res), col = "blue", 
    main = "Demande", xlab = "Residuals")
plot(y = as.numeric(ols$res), 
    x = as.numeric(dataWX$qi), 
    col = "red", 
    main = "Demande", 
    ylab = "Fitted - résidus", xlab = "Real")
points(y = as.numeric(ols$fit), 
    x = as.numeric(dataWX$qi), 
    col = "blue", pch = 17)
lines(y = as.numeric(ols$fit) + as.numeric(ols$res), 
    x = as.numeric(dataWX$qi),
    col = "black")
legend(x = "bottomright", legend = c("Résidus", "Fitted", "Real"),
    col = c("red", "blue", "black"), xpd = NA,
    cex = 1, lwd = 3)
# plot(density(ols$eq[[1]]$res), col = "blue", 
#     main = "Demande", xlab = "Residuals")
# lines(density(wls$eq[[1]]$res), col = "green")
# lines(density(sur$eq[[1]]$res), col = "red")
# plot(density(sur$eq[[2]]$res), col = "red", 
#     main = "Offre", xlab = "Residuals")
# lines(density(wls$eq[[2]]$res), col = "green")
# lines(density(ols$eq[[2]]$res), col = "blue")
# legend(x = "topright", legend = c("OLS", "WLS", "SUR"),
#     col = c("blue", "green", "red"), xpd = NA,
#     cex = 1, lwd = 3)
```


```{r echo = FALSE}
## Les résidus contre la variable prédite 
# par(mfrow = c(1,2), cex = 0.5)
# plot(y = ols$eq[[1]]$res, x = ols$eq[[1]]$fit,
#     col = "blue", 
#     main = "Demande", 
#     ylab = "Residuals", xlab = "Fitted")
# points(y = wls$eq[[1]]$res, x = wls$eq[[1]]$fit,
#     col = "green", pch = 17)
# points(y = sur$eq[[1]]$res, x = sur$eq[[1]]$fit,
#     col = "red", pch = 14)
# plot(x = ols$eq[[2]]$res, y = ols$eq[[2]]$fit,
#     col = "blue", 
#     main = "Offre", 
#     ylab = "Residuals", xlab = "Fitted")
# points(y = wls$eq[[2]]$res, x = wls$eq[[2]]$fit,
#     col = "green", pch = 17)
# points(y = sur$eq[[2]]$res, x = sur$eq[[2]]$fit,
#     col = "red", pch = 14)
# legend(x = "topright", legend = c("OLS", "WLS", "SUR"),
#     col = c("blue", "green", "red"), xpd = NA,
#     cex = 1, lwd = 3)
```

## Les résultats 2SLS, W2SLS, 3SLS et i3SLS
```{r include = FALSE}
# equations
eqdemand = qi ~ 0 + ipi + ri
eqoffer = qi ~ 0 + ipi + si + iki 
inst = ~ ri + si + iki
system = list(Demande = eqdemand, Offre = eqoffer)
# 2SLS
# 2SLS is an equivalent of ILS (indirect least squares)
sls2 = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "2SLS")
# 2WSLS
wsls2 = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "W2SLS")
# 3SLS (errors correction)
sls3 = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "3SLS")
# FIML (iterated 3SLS)
fiml = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "3SLS", maxit = 1000)
```


```{r echo = FALSE, results = "asis"}
texreg(list(sls2, wsls2, sls3, fiml),
    custom.model.names = c("2SLS", "W2SLS", "3SLS", "i3SLS"),
    label = "table : 2sls, w2sls, 3sls and fiml")
```


## Comparaison des modèles  
```{r include = FALSE}
h1 = hausman.systemfit(sls2, sls3) # p = 1, 3SLS inconsistent
# 2SLS estimator is consistent
h2 = hausman.systemfit(sls2, fiml)
res = data.frame(Test = c("2SLS contre 3SLS", "2SLS contre i3SLS"),
    Resultats = c(h1$p.val, h2$p.val))
```


```{r echo = FALSE, results = "asis"}
stargazer(res, 
    title = "Hausman 3SLS consistency test",
    summary = F, 
    header = F)
```


```{r include = FALSE}
# - Linear test :
# What should be tested ???
# linearHypothesis(sls2, 
lr = lrtest(sls2, sls3, fiml)
```


```{r include = FALSE}
xtable(lr, 
    caption = "Likelihood test",
    align = "l|rrrrr")
```
 

## Le comportement des résidus 
```{r include = FALSE}
ShapT = data.frame(nrow = 2, ncol = 6)
ShapT[1,1] = shapiro.test(sls2$eq[[1]]$res)$p.val
ShapT[2,1] = shapiro.test(sls2$eq[[2]]$res)$p.val
ShapT[1,2] = shapiro.test(sls3$eq[[1]]$res)$p.val
ShapT[2,2] = shapiro.test(sls3$eq[[2]]$res)$p.val
ShapT[1,3] = shapiro.test(fiml$eq[[1]]$res)$p.val
ShapT[2,3] = shapiro.test(fiml$eq[[2]]$res)$p.val
colnames(ShapT) = c("2SLS", "3SLS", "i3SLS")
rownames(ShapT) = c("Equation de demande", "Equation d'offre")
```


```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk normality test")
```


```{r include = FALSE}
resdata3 = dataWX %>% 
    mutate(u1 = sls2$eq[[1]]$res,
        u2 = sls2$eq[[2]]$res,
        u3 = sls3$eq[[1]]$res,
        u4 = sls3$eq[[2]]$res,
        u5 = fiml$eq[[1]]$res,
        u6 = fiml$eq[[2]]$res)
```
```{r include = FALSE}
BartT = data.frame(ncol = 3, nrow = 2)
BartT[1,1] = ols_test_bartlett(resdata3, u1, group_var = ndep)$pval
BartT[2,1] = ols_test_bartlett(resdata3, u2, group_var = ndep)$pval
BartT[1,2] = ols_test_bartlett(resdata3, u3, group_var = ndep)$pval
BartT[2,2] = ols_test_bartlett(resdata3, u4, group_var = ndep)$pval
BartT[1,3] = ols_test_bartlett(resdata3, u5, group_var = ndep)$pval
BartT[2,3] = ols_test_bartlett(resdata3, u6, group_var = ndep)$pval
colnames(BartT) = c("2SLS", "3SLS", "i3SLS")
rownames(BartT) = c("Equation de demande", "Equation d'offre")
```


```{r echo = FALSE, results = "asis"}
stargazer(BartT,
    header = FALSE,
    summary = FALSE,
    title = "Bartlett heteroscedasticity test")
```
 

## Les PDF des résidus 
```{r echo = FALSE}
par(mfrow = c(1,2), cex = 0.5)
plot(density(sls2$eq[[1]]$res), col = "blue", 
    main = "Demande", xlab = "Residuals")
lines(density(fiml$eq[[1]]$res), col = "green")
lines(density(sls3$eq[[1]]$res), col = "red")
plot(density(sls3$eq[[2]]$res), col = "red", 
    main = "Offre", xlab = "Residuals")
lines(density(fiml$eq[[2]]$res), col = "green")
lines(density(sls2$eq[[2]]$res), col = "blue")
legend(x = "topright", legend = c("2SLS", "i3SLS", "3SLS"),
    col = c("blue", "green", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

## Les résidus contre la variable prédite  
```{r echo = FALSE}
par(mfrow = c(1,2), cex = 0.5)
plot(y = sls2$eq[[1]]$res, x = sls2$eq[[1]]$fit,
    col = "blue", 
    main = "Demande", 
    ylab = "Residuals", xlab = "Fitted")
points(y = fiml$eq[[1]]$res, x = fiml$eq[[1]]$fit,
    col = "green", pch = 17)
points(y = sls3$eq[[1]]$res, x = sls3$eq[[1]]$fit,
    col = "red", pch = 14)
plot(y = sls2$eq[[2]]$res, x = sls2$eq[[2]]$fit,
    col = "blue", 
    main = "Offre", 
    ylab = "Residuals", xlab = "Fitted")
points(y = fiml$eq[[2]]$res, x = fiml$eq[[2]]$fit,
    col = "green", pch = 17)
points(y = sls3$eq[[2]]$res, x = sls3$eq[[2]]$fit,
    col = "red", pch = 14)
par(xpd = NA)
legend(x = "topright", legend = c("2SLS", "i3SLS", "3SLS"),
    col = c("blue", "green", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

## Les résidus et les prédictions pour i3SLS  
```{r echo = FALSE}
par(mfrow = c(1,2), cex = 0.5)
plot(y = fiml$eq[[1]]$res, x = as.numeric(resdata3$qi),
    col = "red", pch = 17, 
    main = "Demande", 
    ylab = "Fitted - résidus", xlab = "Real")
points(y = fiml$eq[[1]]$fit, x = resdata3$qi, 
    col = "blue", pch = 17)
lines(y = fiml$eq[[1]]$fit + fiml$eq[[1]]$res, x = resdata3$qi,
    col = "black")
legend(x = "bottomleft", legend = c("Résidus", "Fitted", "Real"),
    col = c("red", "blue", "black"), xpd = NA,
    cex = 1, lwd = 3)
plot(y = fiml$eq[[2]]$fit, x = as.numeric(resdata3$qi), 
    col = "blue", pch = 17, 
    main = "Offre", 
    ylab = "Fitted - résidus", xlab = "Real")
points(y = fiml$eq[[2]]$res, x = resdata3$qi,
    col = "red", pch = 14)
lines(y = fiml$eq[[2]]$fit + fiml$eq[[2]]$res, x = resdata3$qi,
    col = "black")
```

## L'autocorrelation 
```{r include = FALSE}
# Panel Durbin-Watson test
# Create dataframe
resdataDW = resdata3 %>% 
    group_by(ndep) %>%
    mutate(u1_diff = u1 - dplyr::lag(u1),
        u2_diff = u2 - dplyr::lag(u2),
        u3_diff = u3 - dplyr::lag(u3),
        u4_diff = u4 - dplyr::lag(u4),
        u5_diff = u5 - dplyr::lag(u5),
        u6_diff = u6 - dplyr::lag(u6)) %>%
    ungroup() %>%
    select(contains("u")) %>%
    mutate_all(function(x) replace_na(x, 0)) %>%
    summarise_all(function(x) sum(x^2))
# Calculate test statistics
pDW = data.frame(ncol = 3, nrow = 2)
pDW[1,1] = resdataDW[1,1]/resdataDW[1,7]
pDW[2,1] = resdataDW[1,2]/resdataDW[1,8]
pDW[1,2] = resdataDW[1,3]/resdataDW[1,9]
pDW[2,2] = resdataDW[1,4]/resdataDW[1,10]
pDW[1,3] = resdataDW[1,5]/resdataDW[1,11]
pDW[2,3] = resdataDW[1,6]/resdataDW[1,12]
# Rename
colnames(pDW) = c("2SLS", "3SLS", "i3SLS")
rownames(pDW) = c("Equation de demande", "Equation d'offre")
```


```{r echo = FALSE, results = "asis"}
stargazer(pDW, 
    header = FALSE,
    title = "Durbin-Watson test statistics",
    summary = F)
```


## L'autocorrelation sur 2 dimentions pour i3SLS
```{r echo = FALSE}
par(mfrow = c(1,2), cex = 0.5)
acf(fiml$eq[[1]]$res, main = "Demande")
acf(fiml$eq[[2]]$res, main = "Offre")
```

## L'independance des résidus  
```{r include = FALSE}
cormat = cor(resdata3[,-c(6,7)])
cormat = cormat[1:5, 6:11]
colnames(cormat) = c("2SLS D", "2SLS O", 
        "3SLS D", "3SLS O",
        "i3SLS D", "i3SLS O")
rownames(cormat) = c("Vin", "IP", 
        "Surface", "Revenus", 
        "Pesticides")
```


```{r echo = FALSE, results = "asis"}
xtable(round(cormat, 4), 
    caption = "Correlation des résidus",
    align = "l|rrrrrr")
```

## Clusterisation
```{r include = FALSE}
# Clustering 
# Between dataframe
dataB = datap 
dataB$qi = Between(datap$qi)
dataB$ipi = Between(datap$ipi)
dataB$iki = Between(datap$iki)
dataB$si = Between(datap$si)
dataB$ri = Between(datap$ri)
dataB$ndep = index(datap)$ndep
# Between correction
dataB = dataB %>% 
    dplyr::select(-t)
dataB = dataB %>% 
    group_by(ndep) %>% 
    summarise_all(mean)
# Analysis for clustering
wss = (nrow(dataB[,-1])-1)*sum(apply(dataB[,-1], 2, var))
for (i in 2:15) {
    wss[i] = sum(kmeans(iter.max = 100, dataB[,-1], centers = i)$withinss)
}
```

```{r echo = FALSE, fig.cap = "Le choix des clusters"}
plot(1:15, wss, type = "l", 
    xlab = "Nomber de clusters",
    ylab = "WSS") # 3, 4, 5
points(1:15, wss, col = "red")
```

```{r include = FALSE}
dataWi = as.data.frame(dataW) 
dataWi$ndep = as.factor(index(dataW)$ndep)
```

```{r include = FALSE}
# Grouping
fit1 = kmeans(iter.max = 100, dataB[,-1], 3)
# Sup 

nclef = data.frame(ndep = dataB$ndep, clust = fit1$cluster)
dataWY = left_join(dataWi, nclef, by = "ndep")
```

## Modèlisation

```{r include = FALSE}
# Data transformation
dataWY = dataWY %>% 
    mutate(ipi1 = ipi*as.numeric(clust == 1),
        ipi2 = ipi*as.numeric(clust == 2),
        ipi3 = ipi*as.numeric(clust == 3),
        ri1 = ri*as.numeric(clust == 1),
        ri2 = ri*as.numeric(clust == 2),
        ri3 = ri*as.numeric(clust == 3),
        si1 = si*as.numeric(clust == 1),
        si2 = si*as.numeric(clust == 2),
        si3 = si*as.numeric(clust == 3),
        iki1 = iki*as.numeric(clust == 1),
        iki2 = iki*as.numeric(clust == 2),
        iki3 = iki*as.numeric(clust == 3))
```

```{r include = FALSE}
# Equations
eqdemandz = qi ~ 0 + ipi +
    ri1 + ri2 + ri3 
eqofferz = qi ~ 0 + ipi + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
instz = ~ ri1 + ri2 + ri3 + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
systemz = list(Demande = eqdemandz, Offre = eqofferz)
```

```{r include = FALSE}
# OLS
olsx = systemfit(systemz, 
    data = dataWY, 
    method = "OLS")
# 2SLS
sls2x = systemfit(systemz, 
    inst = instz,
    data = dataWY, 
    method = "2SLS")
# 3SLS
sls3x = systemfit(systemz, 
    inst = instz,
    data = dataWY, 
    method = "3SLS")
```

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(olsx, sls2x, sls3x),
    custom.model.names = c("OLS", "2SLS", "3SLS"),
    label = "table : ols, 2sls et 3sls, full information clusters")
```

# Conclusions 
```{r eval = FALSE, include = FALSE}
#####################################################
###################  Modèlisation  ##################
#####################################################
```

## Conclusions 
- Le marché du vin
- Le rôle des pésticides  
- Validité 

## Le marché du vin
- Un comportement inattendus 
    - Les effets de substitution contre les produits de la haute gamme 
    - Les effets négatives du revenu 
    - 

## Le rôle des pésticides
- Confirmation des résultats des études précedentes 
    - Utilisés pour réduire les pertes 

## Validité 
- Faible validité du modèle économétrique 
    - Variables ommises 

## Bibliographie 
- Cembalo L., Caracciolo F., & Pomarici E. (2014). "Drinking cheaply : the demand for basic wine in italy." *Australian Journal of Agricultural and Resource Economics*, 58(3). 374-391.
- Butault J-P., Delame N., Jacquet F. & Zardet G. (2011). "L'utilisation des pesticides en France: état des lieux et perspectives de réduction." *Notes et études socio-économiques*, 35. 7-26
- Pujol J. (2017). "Apports des produits phytosanitaires en viticulture et climat : une analyse à partir des enquêtes pratiques culturales." *Agreste Les Dossiers*. 39. 3-25
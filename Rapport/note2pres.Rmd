---
title: "Etude des effets des pesticides dans la production des vins de table"
shorttitle : "Les effets des pesticides"
subtitle: "Analyse empirique des marchés"
author: Arnaud Blanc, Nikita Gusarov, Sasha Picon
shortauthor : A.Blanc, N.Gusarov, S.Picon
institute: Université Grenoble Alpes
shortinstitute: UGA
date: 25/12/2019  
# header-includes:
#     - \usepackage{array}
#     - \usepackage{multicol}
#     - \usepackage{graphicx}
#     - \usepackage{placeins}
#     - \usepackage{xcolor}
output: 
    pdf_document:
        # template: Template.tex
        # slide_level: 2
        # fonttheme: "structurebold"
        toc: false
        # toc_depth: 1
        df_print: "kable"
        fig_width: 6
        fig_height: 3
        fig_caption: yes
        number_sections: FALSE
        includes:
            in_header: packages.sty
            before_body: toc.sty
fontsize: 11pt
bibliography: biblio.bib
# geometry: margin = 0.5in
---

```{r include = FALSE}
###################
# Setting r options
###################
# Knitr options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(size = "tiny")
knitr::opts_chunk$set(dpi = 600)
knitr::opts_chunk$set(fig.align = "center") 
knitr::opts_chunk$set(fig.pos = "!htbp")
```

```{r include = FALSE, eval = FALSE}
#########################
# Extract R code from Rmd
#########################
# require(knitr)
# purl("./Presentation/Presentation.Rmd", 
#     output = "./Presentation/CodePresentation.R", 
#     documentation = 0)
```

```{r include = FALSE}
##########
# Packages
##########
# Results printing
require(stargazer)
require(texreg)
require(xtable)
options(xtable.comment = FALSE)
# Statistics
require(systemfit) # System equations
require(AER) # IV regression
require(olsrr) # Stat tests
require(plm) # Panel data
require(Formula)
# Plots 
require(gridExtra)
# Maps
require(raster)
# General packages
require(tidyverse)
require(rlang)
require(dummies)
require(dplyr)
# R options
options(warn = -1)
```

```{r include = FALSE}
##############
# Loading data
##############
# Data
data = read.csv("../Donnees/Base-de-donnees-indice-prix.csv")
# names(data)
# Arrange
dn = data %>%
    filter(s_vin_simple != 0 & 
        (q_rouge + q_blanc) != 0 &
        (qk_prod + ql_prod) != 0 &
        IP != 0) %>%
    na.omit() %>%
    group_by(ndep) %>%
    count() %>% 
    filter(n == 5) # %>%
    # dplyr::select(ndep)
    # May be interesting to exclude Moselle (57)
datax = data %>% 
    filter(ndep %in% dn$ndep) 
datay = datax %>% 
    filter(annee == 2012) %>%
    mutate(refqki = qk_prod + ql_prod) %>% 
    dplyr::select(ndep, refqki) 
datax = left_join(datax, datay)
datax = datax %>%
    mutate(IQK = (qk_prod + ql_prod)/refqki)
```

```{r include = FALSE}
##################
# Transformed data
##################
datai = datax %>%
    arrange(ndep) %>%
    mutate(si = log(s_vin_simple + 0.001), 
        qi = log(q_blanc + q_rouge + 0.001), 
        ipi = IP,
        ri = log(revenu.déflaté),
        iki = IQK,
        t = as.integer(as.factor(annee)),
        year = annee) %>%
    dplyr::select(year, ndep, qi, ipi, si, ri, iki, t)
```

```{r include = FALSE}
############
# Panel data
############
datap = pdata.frame(datai, index = c("ndep", "year"),
    drop.index = T)
```

```{r include = FALSE}
###################
# Support functions
###################
# STATA version
#######
# xtsum (overall, within and between variance) for panel data
#######
xtsum = function(data, varname, unit) {
    # the variable to xtsum over
    varname = enquo(varname)
    # the identifier dimention
    loc.unit = enquo(unit)
    # overall
    ores = data %>% 
        summarise(ovr.mean = mean(!! varname, na.rm = TRUE), 
        ovr.sd = sd(!! varname, na.rm = TRUE), 
        ovr.min = min(!! varname, na.rm = TRUE), 
        ovr.max = max(!! varname, na.rm = TRUE), 
        ovr.N = sum(as.numeric((!is.na(!! varname)))))
    # between
    bmeans = data %>% 
        group_by(!! loc.unit) %>% 
        summarise(meanx = mean(!! varname, na.rm = TRUE), 
        t.count = sum(as.numeric(!is.na(!! varname))))
    bres = bmeans %>% 
        ungroup() %>% 
        summarise(between.sd = sd(meanx, na.rm = TRUE), 
        between.min = min(meanx, na.rm = TRUE), 
        between.max = max(meanx, na.rm = TRUE), 
        units = sum(as.numeric(!is.na(t.count))), 
        t.bar = mean(t.count, na.rm = TRUE))
    # within
    wdat = data %>% 
        group_by(!! loc.unit) %>% 
        mutate(W.x = scale(!! varname, scale = FALSE))
    wres = wdat %>% 
        ungroup() %>%  
        summarise(within.sd = sd(W.x, na.rm = TRUE), 
        within.min = min(W.x, na.rm = TRUE), 
        within.max = max(W.x, na.rm = TRUE))
    # results
    return(list(var = varname, ores = ores, bres = bres, wres = wres))
}
####################################
# Print results for a list of xtsums
####################################
print.xtsum = function(xtsums.list) {
    # takes multiple xtsums as list
    df = data.frame(Variable = NA, Mean = NA,
        Overall = NA, Between = NA, Within = NA)
    # Filling loop
    for (i in 1:length(xtsums.list)) {
        df[i,1] = as_name(xtsums.list[[i]]$var)
        df[i,2] = xtsums.list[[i]]$ores$ovr.mean 
        df[i,3] = xtsums.list[[i]]$ores$ovr.sd
        df[i,4] = xtsums.list[[i]]$bres$between.sd
        df[i,5] = xtsums.list[[i]]$wres$within.sd
    }
    # Rownames
    rownames(df) = df[,1]
    # Results
    return(df = df[,-1])
}
#################
# Effects testing 
#################
Effect.testing = function(Formulas, data) {
    Dtest = data.frame(var = 0,
        Random = 0, Fixed = 0, 
        Individual = 0, Time = 0, Twoways = 0)
        for (i in 1:length(Formulas)) {
            Dtest[i,1] = names(Formulas)[i]
            ## Chow test
            # Random coefs for random effects          
            Dtest[i,2] = pooltest(Formulas[[i]],
                data = data,
                model = "random")$p.val 
            # Different coefs for fixed effects
            Dtest[i,3] = pooltest(Formulas[[i]],
                data = data,
                model = "within")$p.val
            ## Lagrange multiplier tests
            # Individual effects
            Dtest[i,4] = plmtest(Formulas[[i]],
                data = data,
                effect = "individual",
                type = "bp")$p.val
            # Time effects
            Dtest[i,5] = plmtest(Formulas[[i]],
                data = data,
                effect = "time",
                type = "bp")$p.val
            # Two-ways effects (individual and time)
            Dtest[i,6] = plmtest(Formulas[[i]],
                data = data,
                effect = "twoways",
                type = "ghm")$p.val   
        }
    rownames(Dtest) = Dtest[,1]
    return(Dtest = Dtest[,-1])
}
```

```{r include = FALSE}
##################
# Set ggplot style
##################
pres_theme = theme(text = element_text(size = rel(3)),
    legend.position = "none")
```

# Introduction

```{r eval = FALSE, include = FALSE}
####################################################
################### Introduction ###################
####################################################
```

Aujourd’hui, l’utilisation des pesticides est un problème majeur de l’agriculture. 
Celle-ci utilise la plus grande partie des pesticides en France. 
Il s’agit d’un enjeu à la base du développement durable car ils ont un impact important sur les risques environnementaux et sanitaires. 

Les pesticides sont utilisés dans l’agriculture pour protéger la production. 
Ils sont supposés protéger les rendements. 
En effet, les aléas climatiques influencent le développement de champignons ou de maladies. 
Ainsi, les pesticides permettent de protéger les cultures contre les aléas climatiques et de ne pas perdre de production. 

Dans ce travail nous cherchons à comprendre et à estimer les effets des pesticides sur le marché des vins simples.
De cette façon nous chercherons à étudier l'équilibre sur le marché des vins simples ce qui est sensé nous donner des résultats plus précis et fiables.

# 1. Les pesticides

```{r eval = FALSE, include = FALSE}
####################################################
###################  Pesticides  ###################
####################################################
```

Pour lutter contre l’utilisation des pesticides l’Etat Français et l’union européenne ont mis en place des mesures. 
Ainsi, l’Etat Français lors du grenelle de l’environnement de 2006 a fixé ses objectifs. 
Ainsi, le plan ECOPHYTO 2018 visait à réduire de 50% l’utilisation des pesticides de synthèse. 
Le deuxième objectif est le passage en agriculture biologique à 6% de la surface agricole utilisée en 2010 et vise 20% en 2020.[@Butault2011]

En 2008, les 30 produits les plus toxiques sont interdits. 
Une taxe sur les phytosanitaires a aussi été mise en place. 
Cette taxe est croissante avec le niveau de toxicité de ces produits. 
Elle devait augmenter au fil des années. De plus, l’octroi de crédits d’impôt en faveur de l’agriculture biologique devait aussi permettre de réduire l'utilisation des pesticides.[@Butault2011]

Malgré tous ces efforts, l’utilisation des pesticides perdurent.  
En 2008, le nombre de doses unités (Nodu) a été créé pour enregistrer l’évolution de la demande de pesticides.[@Butault2011]
On remarque que les doses utilisées augmentent de 12% en 2014-2016 par rapport à 2009-2011.  

## Etat actuel

Contrairement aux attentes des autorités, on ne remarque aucune baisse de l’utilisation de pesticides. 
Le Nodu a connu une hausse de 23% entre 2008 et 2017. 
Certaines critiques ont été faites sur l’utilisation du Nodu. 
Il est possible d’utiliser le nombre de substances actives utilisées. 
Mais, cet indicateur connaît lui aussi une hausse de 15% entre 2011 et 2017. 

Néanmoins, les politiques ont quand même eu quelques effets positifs, puisque l’achat des produits les plus dangereux baisse de 6% en 2017. [@Moghaddam2019] 
Les grandes cultures sont les premières utilisatrices de pesticides. 
Elles représentent 67,4% de l’utilisation de pesticides. 
La deuxième culture est celle de la vigne ce qui représente 14,4%  des pesticides utilisés [@Butault2011], ce qui la rend d'un intérét particulier à étudier.

## Comment baisser l'utilisation de pesticides

Afin de baisser l’utilisation des pesticides, des méthodes de cultures ont été développées. 
Il est possible d’utiliser différents mode de culture. 
On peut en retenir trois principaux. 

- l’agriculture intensive, qui ne limite pas le recours aux pesticides ;
- l’agriculture raisonnée, qui limite le recours aux pesticides en fonction de seuils ;
- l’agriculture biologique, qui vise à supprimer les traitements avec des produits phytosanitaires de synthèse. 

Néanmoins, ces méthodes sont difficiles à mettre en place dans la viticulture, ce qui nous amène à un problème de compréhension des raisons pour lesquels les agriculteur utilisent les pesticides.
Les professionnels proposent de commencer par utiliser l’agriculture raisonnée en viticulture qui permettra de réduire les doses de pesticides légales. 
Ensuite l’agriculture doit se déplacer vers l’agriculture biologique qui n’utilise aucun produit phytosanitaire de synthèse. 
Ces propositions sont purement théoriques puisque l'on ne connait pas encore les techniques qui pourraient influencer le comportement des viticulteurs. 
Un des mécanisme possible est le mécanisme du marché. 
En manipulant l'offre et la demande du vin le but est théoriquement atteignable. 

# 2. Le marché du vin français

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Viticulture  ###################
#####################################################
```

La France est l’un des principaux producteurs de vins. En effet, la France représente 10% de la surface des vignes mondiales. La production de vins représentait 4.6 milliards  de litres. La France représentait 17% de la production totale de vins. 3% de la surface agricole française est consacrée à la production des vins. Néanmoins, le vin représente 15% de la production agricole en valeur. [@CNIV2018]
La France est aussi l’un des principaux consommateurs de vins. En effet, en France, il s’agit de la boisson alcoolisée la plus consommée. 88% des ventes de vins en France sont effectuées en grande surface. Néanmoins, la consommation française de vin baisse depuis une trentaine d’années. [@CNIV2018] 

## Utilisation des pesticides dans la viticulture

Nous avons déjà montré que la viticulture est le deuxième secteur agricole en termes d’utilisation des pesticides. En effet, elle représente plus de 14.4% des dépenses de produits phytosanitaires,  en France. Néanmoins, ces pesticides ne sont pas utilisés dans la même proportion dans toutes les régions de France. [@Butault2011] 

Les bassins viticoles Français utilisent en majorité des fongicides et des bactéricides. En effet, la vigne fait face à des aléas climatiques qui permettent le développement de champignons comme le Mildiou. [@Pujol2017] 
Pour lutter contre le développement de ces champignons, les viticulteurs ne peuvent utiliser que des fongicides. En effet, ils ne peuvent pas utiliser la rotation des cultures qui pourrait réduire ou empêcher le développement de ces champignons puisque la vigne est une culture pérenne. Les pieds de vigne ne sont pas replantés chaque année. Il est donc nécessaire d’utiliser les pesticides dans la vigne pour protéger la production et éviter les pertes. En effet, les champignons s’attaquent aux feuilles de la vigne et aux fruits. Donc la pulvérisation de pesticides est un des seuls moyens pour protéger les rendements des cultures viticoles.  Néanmoins, l’utilisation des pesticides a aussi un impact du côté de la demande de vin. Cet impact est plus ambigu, à cause d’un manque de transparence d’information sur les bouteilles de vin. [@Prudent2018]

Un sondage de l’Ifop sur les habitudes et perceptions de consommation des Français a montré que 93% des Français considèrent que la présence de pesticides dans les aliments a un impact sur la santé. 89% des Français souhaiteraient être informés de la présence ou non de pesticides dans les produits alimentaires, à travers un étiquetage. [@Ifop2017]

Il est particulierement intérressant et avantageux d'étudier le marché du vin afin d'identifier les méchanismes éventuels qui influencent le montant des pesticides utilisés dans la production. 
Dans cette étude nous visons à comprendre les méchanismes figurant dans ces relations.

## Le problème d'hétérogénéité

Mais comment étudier le marché du vin ?
Le secteur du vin est constitué de produits qui sont fortement hétérogènes.
En effet, il existe une forte hétérogénéité entre les différents labels (AOP, IGP, sans IG) mais aussi au sein de ces labels. 

Dans le commerce du vin, il est courant de diviser les vins en deux grandes classes en fonction de leurs prix [@cembalo2014] : 

- les vins de qualité inférieure, les moins chers avec des caractéristiques de qualité de base ;
- les vins de qualité supérieure plus chers, dotés de caractéristiques qualitatives complexes et d'une image de grande valeur.

De plus, pour les vins français, selon @steiner2004, le système européen de classification des "*vins de qualité produits dans certaines régions*" (VQPRD) contient à la fois des vins AOC et des "*vins de haute qualité provenant d'un vignoble régional agréé*" (VDQS). 
Les vins de cépage appartiennent à la catégorie des vins autres que VQPRD, qui comprend les \textbf{vins de table} et les \textbf{vins de pays}.

En tenant compte des spécificités du marhcé du vin français, nous utilisons la méthodologie du ministère de l'agriculture et divisons le marché en deux parties :

- La gamme haute (les vins IGP et AOP, vendus dans des magasins spécifiques) ;
- La gamme basse (les vins sans IG, vendus en grands surfaces).

La première partie est soumise à des règlements spécifiques : limitations des quantités produites, origine contrôlée, un caractère de la demande spécifique. 
De plus, les viticulteurs peuvent être réticents à changer leurs processus de production déjà rafiné au maximum de peur d'avoir des pertes de qualité.

La deuxième, c'est-à-dire le marché des vins moins chers, est un peu plus simple et compréhensible. Elle demeure moins hétérogène @cembalo2014. En effet, les vins qui se situent dans une fourchette de prix étroite sont quasiment homogènes. Ainsi, les vins sans indication géographique ont des attributs intrinsèques simples, une complexité de qualité faible. Il s’agit donc de vins peu différenciés. Nous avons, donc, choisi de nous concentrer sur ces vins sans indication géographique à cause de leur degré d’homogénéité qui est plus fort que pour les autres labels.
Cela nous permet d'analyser le marché par département est non par marques/produits.

## Les vins de table

Le marché des vins sans indication géographique connaît de forte variation. Nous allons donc revenir sur la période qui précède notre étude. Ainsi, en 2011, les transactions de vente de vins rouges ont augmenté de 29%. Les transactions de vins rosés ont également augmenté de 13%. Les transactions de vins blancs augmentaient de 76%. Les prix de ces vins bien que faible connaissent aussi des variations importantes. Ainsi, en 2011, les trois couleurs de vins ont connus des hausses de prix. Les vins rouges ont vu leur prix moyen augmenté de 12%. Le prix moyen des vins rosés a aussi cru de 3 %. Pour finir, le prix moyen des vins blancs ont cru de 13%. Les vins de France sans indication géographique  ont connu une baisse en volume des ventes de 14.6% par rapport à la moyenne des ventes sur la période 2006 à 2010. [@FranceAgriMer2011].

# 3. Le cadre théorique

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Théorie mod  ###################
#####################################################
```

## Les hypothèses théoriques

Comme proposé dans la littérature, notre étude sur les vins non coûteux (non IGP) est effectuée au niveau du pays @cembalo2014 pour deux raisons. 
D'abord, les prix de vente moyen des marchés sont diffèrents en raison des droits de douane à l'importation et des taxes à la consommation différentes [@anderson2011global].
De plus, la perception des produits de consommation varie d'un pays à l'autre [@makela2006].

Le rachat du vin par les enseignes (grand surfaces) peut avoir une impact sur l'offre du vin. 
Nous étudions deux cadres différents en les comparant dans ce travail.
Un type d'interaction pose que les prix sont éxogènes pour les fournisseurs de vin simple, comme cela fut démontré par @kremer2004.
L'autre possibilité suppose qu'il existe quand même des interactions entre l'offre et la demande et que les prix du vin sont endogènes. 
Nous devrions trouver une façon pour formaliser ces deux approches différenets et pouvoir les comparer.

La plupart des bouteilles achetées le sont dans la grande distribution. 
Néanmoins, dans un souci de simplicité nous n'estimerons que la situation sur le marché en amont où les distributeurs achètent leurs bouteilles directement auprès du viticulteur (nous simulons l'indice des prix en amont à partir des prix sur le marché final, disponible dans la base de données de FranceAgrimer). 
Donc, nous supprimerons tous les intermédiaires entre le producteur et le distributeur (les grands enseignes, puisque presque la totalité du vin simple est vendu dans les grandes surfaces).

Quand aux exportations et aux importations, n'ayant pas la possibilité de les contrôler le montant des vins non IGP exportés/importés, nous laissons ces effets au terme d'erreur. 
Nous ignorons complétement les interactions internationales. 
Nous simplifions davantage notre modèle en imposant l'absence des flux du vin entre les départements (ce qui peut être justifié si les grandes enseignes rachètent le vin auprès des viticulteurs et seulement après le redistribuent au sein de leurs chaînes).

```{r include = FALSE}
# Il existe indéniablement, au sein de la grande distribution, une offre différenciée par format de vente : les hypermarchés se sont plutôt spécialisés dans le haut et le milieu de gamme avec une sur-représentation des VQPRD, les supermarchés ont privilégié les AOC à bas prix et les vins de table et de pays tandis que le hard discount se spécialisait dans le bas de gamme
```

Nous supposons que les facteurs de production jouent le rôle de modificateur de l'offre (*supply shifter*) ce qui nous permet d'intégrer les variables déterminants le niveau de la production (telles que la surface ou la quantité de pesticides utilisés) directement dans l'équation d'offre.
Pour information sur les facteurs de production du vin nous référençons les articles de @laporte1996 et de @outreville2010.

Avant de conclure, nous proposons au lecteur une liste exhaustive des suppositions sur le comportement du marché des vins simples. 
Premièrement, nous supposons que chaque département à une fonction de production unique détérminée par des spécificités historiques, les traditions, la législation, le terroir, ainsi que des conditions météorologiques et géographiques.
Les effets sont fixes au niveau départamental et peuvent être isolés par des transformations spécifiques des données (ex : une transformation Within).
Deuxièmement, la quantité vendue sur le marché départamental est racheté (consommé) au sein du même département. 
C'est une hypothèse très restrictive, qui nous eloigne de la réalité, mais nous devons l'adopter si nous voulons intégrer les relations entre l'offre et la demande dans notre modèle. 
Afin de vérifier cette hypothèse nous allons construire plusieurs modèles différents.
Finalement, les effets que l'on vise à estimer sont des effets moyens au niveau départamental.
C'est à dire nous allons obtenir un estimateur des effets moyens pour l'ensemble des départements inclus dans notre analyse, ou des effets moyens au sein des groupes de département, si nous révèlons des differences significatives entre les départements. 
Un autre modèle nous permettra de vérifier et de justifier cette hypothèse.

En ce qui concerne les pesticides, nous supposons d'abord, que l'utilisation des pesticides par les viticulteurs est reliée à la demande sur le vin et les préférences des consomamteurs.
De plus, nous posons, que la demande des pesticides est inélastique au prix, ce qui nous permet d'exclure les interactions entre les fournisseurs de pesticides et les agriculteurs de notre analyse. 
La quantité de pesticides utilisés par les agriculteurs correspond seulement à leurs besoins. 

Pour résumer cette partie,  ce travail va porter sur les effets des pesticides sur l'offre des vins simples. 
Nous allons tester certaines hypothèses sur le comportement et l'organisation des relations sur le marché des vins simples en comparant les différents modèles. 
Puis, nous pourrons choisir entre ces modèles différents le plus vraisamblable, qui nous servira à répondre à la question de recherche. 

## Formalisation 

En formalisant notre modèle théorique de base, nous posons, que l'offre agregée pour toute la France est donnée par l'équation suivante : 

\begin{equation}
    Qo = \sum_{i = 1}^{N} qo_i
\end{equation}

Avec la quantité offerte déterminée par des contraintes de production et le prix sur le marché :

\begin{equation}
    qo_i = a_i + b_i Po_i + c_i X_i
\end{equation}

Où $X$ est un vecteur des variables explicatives influençant la production. 
Dans le cas le plus simple nous ne prenons en compte que les quantités des pesticides utilisées et la surface disponible, alors l'effet $c_{i1} : c_i = (c_{i1}, c{i2})$ représente l'effet de l'utilisation des pesticides dans la production du vin sur l'offre de ce dernier.

Cette équation permet déjà d'estimer les effets de l'utilisation des pesticides sur le marché du vin.
Toutefois il existent deux possibilités sur l'organisation du marché dans ce cas. 
D'abord, dans le cadre le plus simple et probable du point de vue théorique nous supposons, les résultats suivants de @kremer2004, que les prix sont imposés par les grandes enseignes aux distriduteurs de vin simple. 
De l'autre côté, nous pouvons supposer que les prix sont endogènes parce qu'ils sont négociés entre le distributeur et le producteur.
Appelons ce modèle théorique M1 pour le référencer dans le futur, nous permettant de distinguer le cas sans intéraction simultanée entre l'offre et la demande. 

Il faut tenir compte que de cette façon nous ignorons plusieurs effets pervers, tels que :

- La structure du marché interne de la France ;
- La mobilité des produits finis entre des differents départements ;
- L'exportation et l'importation du vin.

Toutefois, ces résultats ne seront valables que dans la situation où la quantité de vin simple offerte sur le marché est déterminée seulement par le producteur et n'est pas lié à la demande. 
Comme nous l'avons vu dans la section précedente, la demande peut influencer les décisions des viticulteurs (ex: le choix de la procédure technique à suivre, d'utiliser ou non les pesticides, etc).
Dans ce cas, nous devrions prendre en compte les intéractions entre l'offre et la demande.
Dans ce but, nous introduisons également la demande dans notre analyse. 

La demande agregée du vin en France peut s'écrire sous la forme suivante :

\begin{equation*}
    Qd = \sum_{i = 1}^{N} qd_i 
\end{equation*}

Où $i \in \{1, ..., N\}$ sont des départements, chacun ayant sa propre fonction de demande unique : 

\begin{equation*}
    qd_i = \alpha_i + \beta_i Pd_i + \gamma_i Z_i 
\end{equation*}

Avec $Z$ étant l'ensemble des variables ayant une influence sur la demande du vin, dans le cas le plus simple nous n'utilisons que les revenus (c'est une des variables les plus utilisées dans des études empiriques sur le marché du vin).

Pour intégrer cette information dans notre *framework* analytique, nous devons construire un système d'équations.
Il existe plusieures façons de le faire. 

Dans le premier cas, nous pouvons essayer de capter les effets au niveau national.
Pour ce faire nous réécrivons les deux équations (de la demande et de l'offre respectivement) sous la forme suivante :

\begin{equation*}
    Q_o = \sum_{i = 1}^{N} (a_i + b_i Po_i + c_i X) = \sum_{i = 1}^{N} a_i + \sum_{i = 1}^{N} b_i Po_i + \sum_{i = 1}^{N} c_i X
\end{equation*}

\begin{equation*}
    Qd = \sum_{i = 1}^{N} ( \alpha_i + \beta_i Pd_i + \gamma_i Z_i ) = \sum_{i = 1}^{N} \alpha_i + \sum_{i = 1}^{N} \beta_i Pd_i + \sum_{i = 1}^{N} \gamma_i Z_i
\end{equation*}

Ce qui nous conduira à un système de deux équations, avec $Qd = Qo$ dans la situation d'équilibre :

\begin{align*}
    Qd & = \sum_{i = 1}^{N} \alpha_i + \sum_{i = 1}^{N} \beta_i Pd_i + \sum_{i = 1}^{N} \gamma_i Z_i \\
    Qo & = \sum_{i = 1}^{N} a_i + \sum_{i = 1}^{N} b_i Po_i + \sum_{i = 1}^{N} c_i X
\end{align*}

Neanmoins, ce cas se révèle être très complexe. 
D'abord, les effets peuvent être différents pour tous les départements, ce qui nous conduira à une augmentation dans le nombre des paramètres à estimer significative. 
De plus, même si tous les effets sont identiques pour l'ensemble des départements, des contraintes au niveau des données peuvent se révèler trop restrictives, réduisant, ainsi à néant la puissance statistique de notre estimateur (ex : le nombre des observations par années est très faible). 
Dans les deux cas nous faisons face à une impasse.

Une des modifications possibles dans ce cas sera l'introduction d'une contrainte supplémentaire au niveau de la demande sur le vin de table.
Afin de pouvoir identifier les effets de toutes les variables par un système d'équations, nous pouvons supposer, que tout le vin produit dans un département est consommé dans le même department. 
Dans ce cas nous pourrions obtenir des estimateurrs pour les effets moyens au niveau départemental.
Toutefois, c'est une supposition forte qui nous éloigne de la réalité. 

Théoriquement, nous pouvons tout de méme ignorer ces effets, car nous visons à estimer les effets moyens pour tous les départements. 
De cette façon, lors de l'agrégation des effets au niveau national en estimant le coefficient moyen unique pour tous les départements nous allons réduire les biais possibles.

Alors,nous pouvons réécrire notre système d'equations sous la forme suivante :

\begin{align*}
  qd_i & = \alpha_{i} + \beta Pd_{i,d} + \gamma Z_{i} \\
  qo_i & = a_i + b Po_{i,o} + c X_{i} \\ 
\end{align*}

Où $qd_i = qo_i$ et $Pd_i = Po_i$, ce qui permet de relier les équations au niveau départemental.
Les coefficients $b$, $c$, $\beta$ et $\gamma$ sont supposés fixes pour tous les départements. Ils nous donnent un estimateur des effets moyens au niveau de la France.
L'effet des pesticides dans la production du vin sera capté par le terme $c_{1} : c = (c_{1}, c_{2})$ dans ce cas.

Néanmoins, nous nous posons la question, comment réagir dans le cas où les effets sont différents pour les differents départements à cause des spécificité des marché locaux, géographiques ou autres ?
On peut supposer, qu'il existe au moins quelques groupes majeures ayant des caractéristiques et des comportements similaires. 
Dans ce cas nous pourrions construire des clusters, qui regroupent des départements ayant des caractéristiques identiques. 
Cela nous permettra de modèliser les effets moyens par cluster en réduisant les biais eventuels.

Ce système peut être formalisé par les $K$ systèmes d'équations suivants :

\begin{align*}
  qd_{i_{c = const}} & = \alpha_{i_{c = const}} + \beta_{c = const} Pd_{i_{c = const},d} + \gamma_{c = const} Z_{i_{c = const}} \\
  qo_{i_{c = const}} & = a_{i_{c = const}} + b_{c = const} Po_{i_{c = const},o} + c_{c = const} X_{i_{c = const}} \\ 
\end{align*}

Où $c$ décrit l'appartenance des départements à un des groupes (clusters).

# 4. Les données

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Données mob  ###################
#####################################################
```

Avant de passer à la discussion des modèles économétriques il nous faut prendre connaissance de la nature des données en notre disposition.
Dans cette partie de notre travail nous allons presenter la base des données utilisé lors de cette étude. 
Nous commencerons par une presentation des sources et des types des données extraits de ces sources. 
Puis, nous procederons avec la déscription des méthodes et thécniques utilisées pour transformer ces données et les rendre traitables. 
Finalement, nous presenterons un dictionnaire des variables pour nos bases des données.

## Sources des données : 

Nous avons utilisé les bases des données suivantes pour notre analyse :

- Les données de ventes de pesticides par département (INERIS)
- Les données sur les prix du vin (France Agrimer)
- Les données sur la population (INSEE)
- Les données sur la production de vin (SSM Finances Publiques)

## Les variables utilisées pour notre modèle

Dans notre étude nous faisons face à un problème avec deux variables endogènes et trois variables exogènes.

Variables endogènes : 
- la quantité totale produite de vin rouge et blanc non IG par département (en hectolitres, en log), 
- le prix moyen des vins rouges-blancs (idice, en log).

Variables exogènes : 
- le revenu médian par département (en euros par personne par année, en log), 
- la surface agricole destinée aux vins de table (en hectares, en log),
- la quantité des pesticides utilisés sur la vigne (indice, en log).

Au niveau des pesticides, on va s’intéresser plus particulièrement aux quantités de produits vendus par département entre 2009 et 2017 utilisés principalement sur les cultures viticoles. 
Il faut faire preuve de vigilance sur le conditionnement des produits qui n’est pas exprimé dans la même unité au sein de cette base : en litres ou en kilos.
Dans notre étude nous allons étudier l'impact de la masse totale des pésticides utilisés.
Pour pouvoir le faire, nous créons un indice qui permet de prendre en compte les évolutions des differents types des produits à la fois.
Nous créons un indice simple :

\begin{equation*}
  P = \frac{\sum_j p_{j, t} q_{j, t}}{\sum_j p_{j, 0} q_{j, 0}}
\end{equation*}

Avec $j$ désignant le produit $j$, et $p$ étant un coefficient de pondération (dans le cas le plus simple $p = 1$).

En ce qui concerne les données sur le prix du vin, on s’intéresse principalement au prix moyen des vins rouge- rosés et blancs sans IG (Indication Géographique) sur la période 2009-2017. 
Ces prix sont déflatés par l’indice des prix à la consommation (base 100 en 2014). 
On ne considère ici que le prix moyen déflaté au niveau national.
Dans le deuxième modèle nous avons besoin de créer artificiellement un estimateur qui va varier par département.
Dans ce but nous créons l'indice de prix du vin de table départementale, calculé de façon suivante :

\begin{equation*}
  P = \frac{p_{rouge, t} q_{rouge, t} + p_{blanc, t} q_{blanc, t}}{p_{rouge, 0} q_{rouge, 0} + p_{blanc, 0} q_{blanc, 0}}
\end{equation*}

Avec $t$ étant l'anée au période $t$.

Au niveau des données sur la population, la variable qui nous intéresse ici est relative au niveau de revenu, exprimée au niveau départemental (laquelle, si besoin nous pourrions facilement aggréger au niveau national). 
Plus précisément, on va utiliser le revenu médian par département.
Il est aussi déflatée de l’indice des prix à la consommation (base 100 en 2014).

Toutes les variables subissent une transformation logarithmique, ce qui nous permet d'interpreter les effets estimés plus facilement. 
Pour un modèle logarithmique nous pourrions traiter les estimateurs obtenus comme l'elasticité de la demande/l'offre par rapport à des facteurs differents. 
Ainsi, nous cherchons particulièrement l'élasticité des quantités offertes sur le marché par rapport à la quantité des pesticides utilisés.

Les propriétés de ces données sont les suivantes :

- Toutes les variables varient par département et par année.
- Le période temporelle comprise dans notre échantillon est de 2012 à 2016.
- Nous ne considérons que les régions produisant du vin. 
- Nous éliminons les effets fixes pour en substrayant les moyennes départamentales.
- Données en panel "cylindrées".
- Nombre des individus large (69 départements, qui produisent le vin simple et qui utilisent des pesticides) et le nombre des périodes pauvre (5 périodes).

# 5. L'étude statistique

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Statistique  ###################
#####################################################
```

Dans cette partie de l'étude nous allons mener une étude exploratoire sur les données collectées. 

De l'étude de la variance pour les données en panel avec des statistiques générales, nous passerons à l'étude de l'interdépendance des variables. 
Puis, nous allons finir avec l'étude des données alternées par une transformation *within*.

## Visualisation au niveau de la France 

Pour la première analyse il peut être intéressant de voir la situation du point de vue géographique. 
Nous visualisons les valeurs moyennes par département des différentes variables (une partie des répresentations se trouve dans l'annexe A1). 
Cette representation nous permet d'obtenir une première intuition sur la répartition spatiale des valeurs clés par département. 
Particulièrement la répartition de la quantité de vin simple vendu par département semble avoir une structure autocorrélée dans l'espace. 
Nous allons, quand même ignorer les intéractions spatiales possibles, parce que notre échantillon ne comprend pas la totalité des départements français (nous avons exclus plusieurs départements qui ne produisent pas du vin simle).
Le comportement des autres variables est similaire.

```{r include = FALSE}
# Creation de la base des données 
SpData = datai %>% 
    group_by(ndep) %>%
    summarise_all(mean) %>%
    dplyr::select(ndep, qi, ipi, iki, ri, si)
# Formes
formes = getData(name = "GADM", country = "FRA", level = 2)
# plot(formes, main = "Carte de la France, départements")
# Index 
ind = match(as.numeric(formes$CC_2), SpData$ndep)
# Data transfer
qisp = SpData[ind, "qi"]
ipisp = SpData[ind, "ipi"]
ikisp = SpData[ind, "iki"]
sisp = SpData[ind, "si"]
risp = SpData[ind, "ri"]
# Writting 
formes$qi = qisp
formes$ipi = ipisp 
formes$iki = ikisp 
formes$ri = risp 
formes$si = sisp 
```

D'abord nous étudions le comportement de la variable dépendante de notre système. 
La quantité de vin sans IG produit par département semble pouvoir être corrélée à partir de la figure suivante.

\FloatBarrier

```{r echo = FALSE, results = "asis", fig.cap = "Les quantité du vin non-IG moyennes par département"}
# Plot 
spplot(formes, "qi", 
    col.regions = colorRampPalette(c('grey96', 'red'))(30),  
    main = list(label = "Quantité du vin produite par département", cex = 0.8))
```

\FloatBarrier

Puis, nous observons le comportement du reste des variables (les représentations graphiques sont groupés dans l'annexe A1).
L'indice des prix se comporte pratiquement comme la quantité de vin produite, car cet indice fut construit par l'intermédiaire de cette variable. 
Les autres moyennes ne semblent pas avoir des structures corrélées dans l'espace au niveau de la France. 
Dans notre analyse nous nous laissons la liberté d'ignorer les effets possibles d'autocorrélation spatiale dans nos données. En effet, au moment de la construction de notre base de données, nous avons ignoré les départements ne produisant pas de vin simple. Mais, ils peuvent quand même jouer un rôle si nous prenions en compte la structure spatiale de nos données. 

## Etude de la variance 

Passons maintenant, à l'étude de la variance. 
Nous allons décortiquer la variance par type (between et within) afin d'obtenir une idée sur le choix préférable de la dimension d'agrégation de nos données, car il se peut que la théorie ne corresponde pas à la réalité (ex: nous faisons face aux effets fixes par année et non par département).

```{r include = FALSE}
lxtsums = list()
# list
lxtsums[[1]] = xtsum(datai, ipi, ndep)
lxtsums[[2]] = xtsum(datai, iki, ndep)
lxtsums[[3]] = xtsum(datai, si, ndep)
lxtsums[[4]] = xtsum(datai, ri, ndep)
lxtsums[[5]] = xtsum(datai, t, ndep)
# results
results = print.xtsum(lxtsums)
rownames(results) = c("Index prix", "Index pesticides",
    "Surface", "Revenus", "Temps")
```

Le tableau suivant regroupe les statistiques déscriptives essentielles : 

- Moyennes 
- Variance sur l'échantillon complet 
- Variance *between* 
- Variance *within*

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(results,  
    header = FALSE,
    title = "Etude de la variance",
    summary = FALSE)
```

\FloatBarrier

Il est facile de remarquer que la variance *between* est plus grande que la variance *within*. 
Cela nous amène à l'idée qu'il faut utiliser un modèle qui permettra d'estimer et de corriger ces inégalités entre les individus, car nous sommes plus interessés par des effets individuels moyens (les effets moyens pour tous les départements).
Cela est complètement conforme à l'hypothèse que l'on a exprimé lors de la formalisation du modèle économique théorique.

```{r include = FALSE}
Formulas = list(
    ipi = qi ~ ipi,
    iki = qi ~ iki,
    si = qi ~ si,
    ri = qi ~ ri)
Dtest = Effect.testing(Formulas, data = datap)
rownames(Dtest) = c("Index prix", "Index pesticides",
    "Surface", "Revenus")
```

De plus, il est intéressant d'observer les résultats obtenus pour le test de Chow comparant le modèle complet (*pooled model*) contre les modèles aux effets fixes et aléatoires. 
Le tableau suivant regroupe les p-valeurs de ce test pour les différents modèles univariées.

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(Dtest[,c(1:2)],  
    header = FALSE,
    title = "Pooling-test de Chow, p-valeurs",
    summary = FALSE)
```

\FloatBarrier

A part le cas de la surface nous ne pouvons pas rejeter l'hypothèse nulle, spécifiant que les individus ont des effets identiques pour toute la population. 

## L'étude des types d'effets  

Nous avons déjà vu, qu'il est fortement probable que nous faisions face à un modèle à effets fixes individuelles. 
Il faut quand même le justifier.
Pour faire cela, nous allons effectuer le test du multiplicateur de Lagrange sur la nature des effets (individuels, temporels ou en double dimension). 
Selon les résultats des tests il est difficile de choisir arbitrairement un type d'effet. 
Il est évident que nous avons des effets fixes au niveau individuel ou des effets fixes en double dimension pour toutes les variables. 

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(Dtest[,c(3:ncol(Dtest))], 
    header = FALSE,
    title = "p-valeurs de Lagrange multiplier test",
    summary = FALSE)
```

\FloatBarrier

Selon les résultats obtenus, ainsi que les évidences théoriques des études antérieurs nous décidons de ne garder que les effets fixes au niveau individuel afin de faciliter l'analyse.

## L'analyse de la corrélation

Dans le tableau A2.2 des annexes nous présentons les corrélations des variables après la correction pour les effets fixes individuels (nous effectuons la transformation *within* sur nos données en soustrayant les moyennes individuelles pour l'ensemble des variables).
Dans les annexes, nous proposons également un tableau de corrélation pour les données non-transformées (A2.1), ce qui permet d'observer les inégalités et une pauvre répresentativitée des liens entres les variables pour les données initiales.
Il est facile à remarquer la corrélation des ordres inférieurs à 0.1 pour toutes les variables sauf les intéractions entre la surface cultivé et la quantité de vin offerte, ce qui explique pourquoi nous n'avons pas le choix et devons passer à la forme *within*.

```{r include = FALSE}
###################
# Rework the matrix WITHIN_TRANSFORM
###################
rm(datax) ; rm(datay) ; rm(data) ; rm(dn)
dataW = datap 
dataW$qi = Within(datap$qi)
dataW$ipi = Within(datap$ipi)
dataW$iki = Within(datap$iki)
dataW$si = Within(datap$si)
dataW$ri = Within(datap$ri)
```

En ce qui concerne les données *within*, particulierement nous pouvons remarquer une forte corrélation entre la quantité offerte et le prix d'équilibre.
Egalement nous observons une corrélation positive suffisamment significative (supérieure en grandeur de 0.2) entre la surface cultivé et la quantité du vin simple sur le marché, aussi bien qu'entre les revenus et l'indice d'utilisation des pesticides (ce qui est probablement juste une coïncidence). 
Finalement, nous remarquons une corrélation négative entre la surface cultivée et l'indice d'utilisation des pesticides, ce qui est tout à fait naturel.

# 6. Modèlisation

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Modèlisation  ##################
#####################################################
```

\noindent\rule[0.5ex]{\linewidth}{1pt} 

\textcolor{red}{Ajouter des liens avec des études méthodologiques precedents.}

\noindent\rule[0.5ex]{\linewidth}{1pt}

Cette partie du travail abordera la formulation économétrique de notre problème.
Nous allons débuter par la présentation des notions théoriques utilisées dans ce travail, suivis par la formalisation économétrique du modèle théorique que nous avons spécifié dans la séction 5.
Après, nous expliquerons la stratégie d'identification utilisée.

## Presentation de la méthodologie

L'AIDS (*almost ideal demand system*) et les autres modèles de demande cités dans la littérature ont de nombreuses lacunes qui les rendent impropres pour l'estimation du marché du vin, selon @cembalo2014. 
Dans notre étude nous allons, tout de même, utiliser une approche similaire à ce modèle là, sous des suppositions restrictives. 

Ce modèle nous permettra de simuler l'équilibre sur le marché du vin, prenant ainsi en compte la plupart des facteurs incitant les producteurs de vin à utiliser les pesticides. 

## Modèle économétrique 

Dans cette section, nous allons présenter un par un nos modèles économétriques correspondant chacun à un des trois cadres théoriques possibles.
Tous les modèles visent à estimer les effets moyens pour tous les départements sous des hypothèses différentes de fonctionnement de marché.
Dans tous les cas, l'agrégation des effets au niveau national (ou au niveau des groupes) nous permet de réduire les biais eventuels, liés à la mauvaise spécification du modèle.

Pour le cadre où nous n'observons pas les intéractions entre la demande et l'offre sur le marché (M1). Nous estimons un modèle simple.
Nous écrivons notre modèle sous la forme suivante :

\begin{equation*}
  qo_{i,t} = a_1 + b Po_{i,t} + c X_{i,t} + u_{i,t}
\end{equation*}

A ce point nous avons un choix : soit nous supposons que les agriculteurs sont des preneurs de prix, ce qui nous permet de traiter le prix comme une variable exogène; soit nous devrions construire un estimateur de variables instrumentales afin de traiter l'endogénéité éventuelle de l'indice des prix.
Evidement le premier cas est le plus simple, mais pour justifier l'utilisation de cette méthode nous devrions effectuer des tests d'endogénéité de prix. 
Le deuxième cas est beaucoup plus réaliste, puisque les viticulteurs sont rarement preneurs de prix et l'offre aussi joue son rôle sur l'équilibre du marché.

Dans la dernière situation nous utilisons les idées de @mackay2018, supposant que les variables déterminant la demande sont des instruments fiables pour la prédiction des variables endogènes dans l'équation d'offre (bien que dans notre cas nous ignorons les effets des intéractions entre l'offre et la demande).
Particulièremnt ici, nous pourrions utiliser les données sur les revenus afin d'instrumenter le niveau des prix (l'indice des prix du vin).

Passons maintenant au modèle plus complexe (M2), basé sur l'hypothèse que la demande influence l'offre, affectant également l'utilisation des pesticides par les agriculteurs.
Nous pouvons réécrire notre système d'équations dans ce cas sous la forme suivante :

\begin{align*}
  qo_{i,t} & = a_1 + b Po_{i,t} + c X_{i,t} + u_{i,t} \\ 
  qd_{i,t} & = \alpha_{i} + \beta Pd_{i,t} + \gamma Z_{i,t} + \epsilon_{i,t}  \\
\end{align*}

Nous posons que l'offre et la demande sont egaux au niveau de chaque département : $qd_{i,t} = qo_{i,t}$.
C'est-à-dire que l'offre interne du département vise à satisfaire la demande interne du même département. 

En termes d'agrégation ex-post des effets estimés, nous sommes sensés tomber sur l'équilibre au niveau du marché national. 
En d'autre mots, le système (qui implique : $Qd = Qo$) :

\begin{equation*}
  qd_{i,t} = qo_{i,t}
\end{equation*}

Au point d'équilibre nous rencontrons également l'égalité des prix :

\begin{equation*}
  Po_{1,t} = Pd_{1,t}
\end{equation*}

De cette façon nous obtenons un système d'équations.
En simplifiant l'écriture nous pouvons la représenter sous la forme suivante :

\begin{align*}
  q_{i,t} & = \alpha_{i} + \beta P_{i,t} + \gamma Z_{i,t} + \epsilon_{i,t} \\
  q_{i,t} & = a_i + b P_{i,t} + c X_{i,t} + u_{i,t}
\end{align*}

Et finalement, nous pouvons estimer les deux modèles (M1 et M2) en regroupant les départements par leurs caractéristiques.
Appelons ces modèles M3.1 et M3.2 respectivement.

Le premier prenant la forme :

\begin{align*}
  qo_{i,t} & = a_1 + b Po_{i,t} + c X_{i,t} + u_{i,t} \\ 
\end{align*}

Tandis que le dernier :

\begin{align*}
  q_{i_{c},t} & = \alpha_{i_{c}} + \beta P_{i_{c},t} + \gamma Z_{i_{c},t} + \epsilon_{i_{c},t} \\
  q_{i_{c},t} & = a_i + b P_{i_{c},t} + c X_{i_{c},t} + u_{i_{c},t}
\end{align*}

Avec $c$ décrivant l'appartenance du département à un des clusters.

Pour finir cette partie, nous avons à notre disposition plusieurs chemins différents pour traiter ce modèle du point de vue économétrique. 
Le plus simple est d'estimer l'effet des pesticides sur l'offre de vin en ignorant les impacts du comportement des consommaterus sur les producteurs. 
Cette méthode implique une estimation par OLS simples (ou IV-OLS, lesquels introduisent la notion d'endogénéité des prix).
De l'autre coté, nous pouvons utiliser les triples moindre carrés (nous devrions comparer les résultats obtenus avec un système d' équations non-réliées, éstimé par 2SLS afin de traiter l'endogenèité), qui nous permettront d'obtenir des résultats identiques aux résultats d'estimations des équations structurelles sous l'hypothèse de l'intéraction entre l'offre et la demande. 
Cette méthode offre la possibilité d'estimer le système d'équations avec plusieurs variables endogènes en prenant en compte les deux coté du marché, à la fois. 
Finalement, si on trouve qu'il existe une hétérogénéité entre les départements en termes d'équilibre interne, nous pourrions réestimer les modèles en clusterisant nos *individus* (départements) par des classes différentes selon leurs attributs, pour estimer les equations par cluster.

## Hypothèses sur les résultats 

Nous attendons que l'estimateur de 3SLS, qui permet de capter les effets de corrélations entre les équations en présence de plusieures variables exogènes nous permettra d'obtenir des estimations plus fiables. 
Cette méthode nous permet à depasser le biais de simultanéité qui apparaît dans le cas d'estimation des systèmes d'équations liés (dans notre cas nous étudions les effets des pesticides sur l'offre et production du vin simple sous l'hypothèse de présence des effets du marché).
L'estimateur pareil donne des résultats similaires à l'estimateur de ILS (*indirect least squares*).
De plus, sa version iterée (qui converge à des résultats similaires à ceux obtenus par l'éstimation avec maximum de vraisamblance) donne des résultats avec la variance la plus faible.

Les propriétés de cet estimateur sont :

- Consistence ;
- Efficience (asymptotique) ;
- La distributions pour les estimateurs suit une loi normale seulement dans des grands échantillons.

Dès le debut nous envisagions que cet estimateur ne reflètera pas la nature du marché. 
C'est pourquoi nous, dans ce travail, testons plusieurs modèles.

Parmi les inconvénients éventuels, on a également la faible représentation des effets hetérogènes entre les départements par le modèle. 
Nous estimons seulement les effets moyens et ainsi nous ignorons les différences des élasticités pour des départements différents. 
Hereusement ce problème peut être rémédié par l'introduction des clusters, regroupant des départements ayant des comportements similaires.

Finalement, il existe des effets que l'on ignore complètement, mais qui risquent d'intervenir. 
Par exemple, nous ignorons la présence d'autocorrélation spatiale et/ou temporelle dans notre modèle. 
Egalement, un nombre probablement insuffisant de facteurs est utilisé dans ce modèle, ce qui augmente le risque du biais des variables omises dans nos estimations. 

# 7. Résultats des estimations 

```{r eval = FALSE, include = FALSE}
#####################################################
###################  Modèlisation  ##################
#####################################################
```

Dans cette section nous allons présenter les résultats économétriques pour les différents modèles et les comparer.

Nous estimons un ensemble de modèles différents possibles afin de pouvoir choisir la méthode la plus raisonnable. 
Les modèles suivants sont traités séparement :

- M1 : modèle simple sans intéraction entre l'offre et la demande ;
- M2 : modèle complexe visant à intégrer les intéractions entre l'offre et la demande en présence de variables éndogènes ;
- M3 : les modèles sur les données clustérisées (M3.1 et M3.2 respectivement pour les deux cas précédents).

```{r include = FALSE, eval = FALSE}
# - Vérification des hypothèses (5 hypothèses) :
#     - La moyenne nulle des erreurs 
#     - La normalité des residus 
#     - Homoscedacité 
#     - Autocorrélation 
#     - Spécification du modèle
# 3SLS and FIML are asymptotically equivalent. 
# Hence 3SLS is efficient and FIML is consistent even if residuals are not normal.
```

## M1 : Les résultats en absence d'intéractions

Dans le cas des modèles sans intéractions avec la demande, nous pouvons séparer deux cas différents.
Le premier, le plus simple, se base sur l'hypothèse, que les prix des vins simples sont imposés aux agriculteurs par les consomateurs (ou, ce qui est beaucoup plus probable, par des grandes enseignes ayant un pouvoir de négociation significatif).
Cela implique que nous pouvons considèrer les prix comme exogènes dans notre modèlisation d'offre et par conséquent estimer notre modèle par des MCO (OLS - *ordinary least squares*) simples.
En ce qui concerne le deuxième cas, nous posons que les prix dans l'equation d'offre sont endogènes. 
C'est-à-dire, les agriculteurs affectent les prix par leur niveau de production et par les quantités émises sur le marché final. 
Afin de traiter ce problème d'endogénéité nous pouvons utiliser la méthode des variables instrumentales (IV-OLS). 
Mais quels instruments choisir ?
Sur ce point nous nous référons au travail de @mackay2018 (et plus particulierement le travail fondateur de @hausman1996valuation), où les auteurs démontrent que les instrument d'offre choisis parmis les régresseurs de l'équation de la demande sont des instruments suffisament pertinents.
Dans notre cas nous pouvons instrumenter les prix par les revenus dans les départements étudiés, ce qui est conforme à la théorie économique, car le niveau des prix doit être corrélé avec le revenu réel.

Neanmoins, nous allons encore vérifier la validité de cet instrument et du modèle résultant.
Par exemple, bien que notre supposition sur l'instrument rentre parfaitement dans le cadre théorique, nous n'observons qu'une faible corrélation entre l'indice des prix et les revenus (voir l'annexe A2.2).
Les revenus ont la pus petite corrélation avec la variable explicative quand même.

Les résultats pour les deux modèles sont présentés dans le tableau ci-aprés : 

```{r include = FALSE}
# Data transformation for systemfit
dataWX = as.data.frame(dataW)
```

```{r include = FALSE}
# Equations
eqoffer = qi ~ 0 + ipi + si + iki  
inst = ~ ri + si + iki
```

```{r include = FALSE}
# OLS
ols = lm(eqoffer, 
    data = dataWX)
# IV-OLS
ivols = ivreg(eqoffer, 
    inst, 
    data = dataWX)
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(ols, ivols),
    custom.model.names = c("OLS", "IV-OLS"),
    custom.coef.names = c("IP", "Surface", "I pésticides"),
    label = "table : ols et ivols",
    caption = "Modèles économétriques, variable dépendante - la quantité du vin vendu (en log)")
```

\FloatBarrier

Avant de commenter les effets estimés, nous devons supposer que le modèle en présence d'endogénéité n'est pas correcte (les estimateurs obtenus sont biaisé et loins de la réalité). 
D'abord, les instruments utilisé pour l'estimer sont asssez faibles et donne pas des résultats pertinents.
De plus, à partir des résultats du test de Wu-Haussman nous pouvons conclure qui nous indique que les estimateurs OLS et IV-OLS sont identiquement consistent et que nous n'avons pas des raisons pour utiliser l'estimateurs de IV-OLS (dans cette situation les résultats obtenus par OLS sont plus efficaces).
Les résultats de ces tests sont regrouppés dans l'annexe X.

Toutefois, les résultats obtenus par l'estimateur de OLS risquent d'être également biaisés.
Dans l'annexe X nous pouvons voir que Shapiro-Wilk test rejette la normalité des résidus de notre modèle (annexe B4), bien que la fonction de répartition partielle a une forme proche à normale (annexe B1).
Nous risquons également d'avoir des biais dans la variance des estimateurs, car selon le test de Bartlett sur l'heteroscedacité nous réjétons l'hypothèse de l'homoscedacité des résidus (annexe B3).
Au moins dans ce cas nous n'avons pas des problèmes avec l'autocorrelation (les résultats du test de Durbin-Watson sont grouppé dans l'annexe B2), ce qui peut s'expliquer par utilisation des données temporelles en série trop courte pour y pouvoir detecter l'autocorrelation.
Les résidus également ne sont pas correlé avec des variables explicatives, mais ont oune correlation forte avec la variable dependante, ce qui nous indique sur la misspécification possible dans notre modèle (annexe B1).
L'explication la plus probable à ce problème est qu'on n'étudie pas suffisament d'effets dans notre modèle et rencontrons par suite le biais de variable omise.
Le graphique des résidus nous montre en même temps la nature quasi-aléatoire des résidus.

Maintenant, passons au résultats obtenus. 
L'indexe des prix a une faible effet positive sur l'équilibre du marché.
Néanmoins il n'est pas trop sensible de commenter ces effets plus précisement, car nous n'avons toujour pas une évidence forte sur sa exogénité.
La surface dediée au vins simples a également un effet positive sur la quantité du vin simple vendu, ce qui est toutà fait naturelle, vu que c'est le facteur principal de production du vin. 
Finalement, nous passons à l'effet le plus interessant dans le contexte de notre étude. 
Nous rappelons à notre lecteur que c'est exactement cet effet, l'effet des pésticides sur le marché du vin, qu'on vise à estimer.
Conformement aux études precedents nous découvrons que les pésticides ont un impact négative sur l'offre du vin simple, ce qui s'explique par leur nature d'utilisation.
C'est-à-dire, nous obtenons une confirmation que les pésticides sont utilisés pour minimiser les pertes par les agriculteurs. 
Particulierement dans le cadre du modèle estimé, l'effet moyen pour l'ensemble des départements est qu'une augmentation de 1% d'utilisation des pésticides est une reponse des agriculteurs à des pértes et de la baisse de l'offre d'au moint de 0.0016%, toutes choses égales par ailleurs.
Les résultats en termes numeriques sont assez ambigus, car nous faisons face à des nombreux problèmes dans la spécification du modèle, quand même nous pouvons constater un effet de minimisation des pertes dans l'utilisation des pésticides.  
Cette nature révele des implications importantes en termes de traitement futur du problème d'utilisation excessif des pésticicdes dans la viticulture.

## M2 : Les résultats dans le cas des effets du marché presents

Dans cette séction nous allons étudier le modèle sous l'hypothèse de présence des effets de la conjoncture sur les décisions des agriculteurs. 
Identiquement au cadre précedent nous avons deux choix possibles. 
D'abord, sous l'hypothèse d'endogénéité des prix nous povons estimer le modèle par le méthode de 3SLS, en introduisant dans notre modèle à la fois l'endogénéité des prix pour l'offre et la demande et la correlation entre les résidus de ces deux équations décrivant le comportement des agents du marché.
Deuxiemement, nous avons la possibilité d'imposer l'exogeneité des prix dans nos équations, ce qui peut être les cas si les enseignes rachetant le vin des agriculteurs sont des preneurs des prix du consommateur final.
Nous allons comparér des résultats des plusieurs modèles afin de verifier sa validité. 

Le prémier modèle éstimé par les 3SLS est complexe et nous risquons d'obtenir des résultats biaisé suite à des misspécification eventuelles.
Afin de contracter la variance des estimateurs les rendant plus efficaces nous pouvons impliquer la procedre i3SLS (*iterated three step least squares*).
Cette méthode nous donne des résultats similaire à ceux obtenus par FIML (*full information maximum likelihood*).
Quand même l'utilisations des procedures itératives ne semble pas donner une diminution dans les variances des estimateurs significative (annexe C1). 

Nous pouvons également comparer les résultats obtenus par 3SLS avec le modèle en absence des intéractions (sous l'hypothèse que les résidus des deux équations ont une correlation nulle) éstimé par 2SLS (*two step least squares*). 
Dans ce cas, les regresseurs endogenes de la demande sont instrumentés tout comme décrit dans @wooldridge2005instrumental.
Ce méthode donne des résultats équivalents à ILS (*indirect least squares*), une téchnique utilisé pour estimer les systémés des équations.

Dans le deuxieme cas nous réjetons l'hypothèse de l'endogénéité des prix pour le marché du vins simple, en supposant qu'il est dicté par le consommateurs final à les acteurs en amont (le distributeur qui rachete le vin d'agriculteur).
Cela nous amène à implementer le méthode SUR (*seamingly unrelated equations*) afin d'introduire la correlation entre les résidus dans notre modèle du marché tout en ignorant l'endogénéité des prix.

Les résultats pour les deux modèles sont régrouppé sous format d'un tableau ci-dessous ("D" désigne les coefficients de l'équation de la demande et "O" de l'équation de l'offre, qui nous interesse) :

```{r include = FALSE}
# Equations
eqdemand = qi ~ 0 + ipi + ri
eqoffer = qi ~ 0 + ipi + si + iki 
inst = ~ ri + si + iki
system = list(Demande = eqdemand, Offre = eqoffer)
```

```{r include = FALSE}
# Equations 
# 2SLS
## 2SLS is an equivalent of ILS (indirect least squares)
sls2 = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "2SLS")
# 3SLS
sls3 = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "3SLS")
# FIML (iterated 3SLS)
fiml = systemfit(system, 
    inst = inst,
    data = dataWX, 
    method = "3SLS", maxit = 1000)
# SUR
sur = systemfit(system,
    data = dataWX, 
    method = "SUR")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(sur, sls3),
    custom.model.names = c("SUR", "3SLS"),
    custom.coef.names = c("D : IP", "D : Revenu", 
        "O : IP", "O : Surface", "O : I pésticides"),
    label = "table : sur et 3sls",
    caption = "Modèles économétriques, variable dépendante - la quantité du vin vendu (en log)")
```

\FloatBarrier

Les résultats obtenus pour le cadre avec les prix endogènes (l'estimation par 3SLS) donne forcement des résultats biaisé, car comme nous avons vu dans la séctions précedente nous ne dispososns pas d'instruments suffisament forts pour instrumenter l'index des prix.
Cela se confirme par la nonsignificativité des indices des prix estimé par l'approche des variables instrumentalles.
Ces effets sont négatives non-differents de zero, ce qui n'est pas normal pour un bien n'étant le bien de Giffen (bien que nous pouvons arbitrer que le vin le plus ismple pourrais se comporter d'une telle façon, car c'est un des produits alimentaires les plus basiques).
Des autres tests nous confirment la misspécification  de ctte modèle : les résidus sont parfaitment correlé avec les valeurs de variable dépendante et les prédictions, ce qui est evident des graphiques dans les annexe C2; une forte hétereroscedacité, qui cette fois est apparente sur les graphiques (annexes C2 et C5), etc.
Quand même les tests de spécification ne donne pas aucune indication de misspécification du modèle 3SLS par rapport au modèle 2SLS, ce qui nous rassure dans notre supposition que nous n'utilisaons pas suffisament des variables explicatives dans notre modèle pour utiliser ces approches économétriqes.

Tout de même, nous obtenons des résultats proches à ceux obtenus par OLS simples dans la séction precedente ($-0.16$ contre $-0.17$). 
Cela confirme notre hypothèse sur le rôle joué par les pésticides dans la propositions du vin simple sur le marché. 
Néanmoins, nous préferions de ne pas utiliser ce modèle comme notre modèle de réference en futur à cause de plusieurs sources des biais.

En ce qui concerne les résultats d'estimation par SUR, nous constatons des effets sont presque idéntiques à ceux, obtenus par l'estimateur OLS simple. 
Bien que dans ce cas les effets d'utilisation des pésticides sont un peu plus accentués, avec un comportement des résidus plus abnormaux.

## M3 : Les résultats pour des départements grouppés

Dans cette séction nous allons commencer par la présentation et la comparaison des differentes téchniques pour la clustérisation de nos données. 
Puis nous allons proceder avec un étude et la modèlisation des données clustérisé. 
Nous suppososn que cet approche peut donner des résultats significativement differents, car nous supposons une forte héterogeneité dans le comportement des differents départements.

Le regrouppement des département dans les clusters par leurs caractéristiques possiblement proches, doit nous permettre de traiter les problèmes d'hétérogénéité possibles (nous pouvons observer des traces de ces effets sur les graphiques dans l'annexe A2).
Cela devra permettre d'ameillorer les résultats des estimations en réduisant la variance de nos estimateurs.

### Clusterisation 

Il existent plusieurs façons de séparer et clustériser les données. 
Nous, dans notre travail, allons implementer la procedure *k-means* ou *k-moyennes*. 
Cette procedure regrouppes les individus autours des *centres* (dont le nombre est *k*) choisis par un algorithme itérative. 
Cet algorithme itérative minimise la distance inta-cluster.
La qualité d'ajustement des clusters est evalué par le paramétre WSS (*within sum of squares*).
C'est exactement ce paramétre la qu'on va utiliser pour comparer les differents approches et en choisir le plus approprié.

En ce qui concerne les differents méthodes de clustérisation, nous pouvons les choisir en manipulant les données à l'entrée (les *inputs*) de cet algorithme.
Plus précisement nous pouvons :

- Groupper les départements en utilisant les valeurs moyennes pluriannuelles de leurs caractéristiques (ce qui est idéntique aux données qu'on obtient lors de la transformation *between*);
- Groupper nos individus en utilisant les variations des caractéristiques intra-annuelles (nous appliquons la transformation *within* à nos données, puis nous trasformons nos données afin de conserver la dimention temporelle);
- Utiliser l'information complete pour capter les évolutions aussi bien que les differences générales entre les département étudiés.

#### *Between* 

Nous supposons que les départements ayant des valeurs moyennes inter-annuelles proches, obtenus par la transformation *between*, ont des caractéristiques proches, ainsi qu'un comportement presque identique.
La clusterisation est effectuée sur les données *between* pour l'ensemble des départements étudiés.

Les résultats des éstimations ainsi que les centres théoriques pour $k = 3$ se trouvent dans l'annexe D1.1.

```{r include = FALSE}
# Clustering 
# Between dataframe
dataB = datap 
dataB$qi = Between(datap$qi)
dataB$ipi = Between(datap$ipi)
dataB$iki = Between(datap$iki)
dataB$si = Between(datap$si)
dataB$ri = Between(datap$ri)
dataB$ndep = index(datap)$ndep
# Between correction
dataB = dataB %>% 
    dplyr::select(-t)
dataB = dataB %>% 
    group_by(ndep) %>% 
    summarise_all(mean)
# Analysis for clustering
wss1 = (nrow(dataB[,-1])-1)*sum(apply(dataB[,-1], 2, var))
for (i in 2:15) {
    wss1[i] = sum(kmeans(iter.max = 500, dataB[,-1], centers = i)$withinss)
}
```

```{r include = FALSE}
# Intermediary data
dataWi = as.data.frame(dataW) 
dataWi$ndep = as.factor(index(dataW)$ndep)
# Grouping
fit1 = kmeans(iter.max = 100, dataB[,-1], 3)
# Key
nclef = data.frame(ndep = dataB$ndep, clust = fit1$cluster)
# Concatenation
dataWY = left_join(dataWi, nclef, by = "ndep")
# Centers
clusters = cbind(fit1$centers, fit1$size, k <- c(1:3)) %>%
    as.data.frame()
```

### *Within*

Dans ce cas nous supposons que les départements ayant des tendances et les évolutions de leurs caractéristiques identiques ont un comportement qui ressamble.
Plus, précisement, nous commençon par la transformation des nos données en *within*, ce qui implique qu'on substrait les moyennes empiriques intra-annuelles pour toutes les caractéristiques.
Après, nous transformons les données créant pour chaque caractéristique pour chaque année une variable séparée, ce qui permet de préserver la dimention temporelle de nos données.

Les centres théoriques obtenus pour $k = 3$ se trouvent dans l'annexe D1.2.

```{r include = FALSE}
# Clustering Within
# Data creation
dataClust = dataWi
dataClust_t1 = dataClust %>% 
    filter(t == 1) %>% 
    dplyr::select(-t)
dataClust_t2 = dataClust %>% 
    filter(t == 2) %>% 
    dplyr::select(-t)
dataClust_t3 = dataClust %>% 
    filter(t == 3) %>% 
    dplyr::select(-t)
dataClust_t4 = dataClust %>% 
    filter(t == 4) %>% 
    dplyr::select(-t)
dataClust_t5 = dataClust %>% 
    filter(t == 5) %>% 
    dplyr::select(-t)
# Joining data
dataC = inner_join(dataClust_t1, dataClust_t2, 
    by = "ndep", suffix = c("", ".t2")) 
dataC = inner_join(dataC, dataClust_t3, 
    by = "ndep", suffix = c("", ".t3")) 
dataC = inner_join(dataC, dataClust_t4, 
    by = "ndep", suffix = c("", ".t4")) 
dataC = inner_join(dataC, dataClust_t5, 
    by = "ndep", suffix = c("", ".t5")) 
# Analysis for clustering
wss2 = (nrow(dataC[,-6])-1)*sum(apply(dataC[,-6], 2, var))
for (i in 2:15) {
    wss2[i] = sum(kmeans(iter.max = 500, dataC[,-6], centers = i)$withinss)
}
```

```{r include = FALSE}
# Grouping
fit2 = kmeans(iter.max = 500, dataC[,-6], 3)
# require(FactoMineR)
nclef2 = data.frame(ndep = as.factor(dataC$ndep), clust = fit2$cluster)
dataWZ = left_join(dataWi, nclef2, by = "ndep")
clusters2 = cbind(fit2$centers, fit2$size, k <- c(1:3)) %>%
    as.data.frame()
# dataWZ %>% filter(clust == 2) %>% select(ndep)
```

### Information complète

Dans le cas de l'information complète nous utilisons l'ensemble des informations disponibles sur les individus afin de construire les clusters. 
Nous utilisons l'approche similaire à celui utilisé dans le cas de clusterisation *within*, sauf que cette fois nous n'effectuons pas la correction sur les valeurs moyennes intra-annuelles.

Les centres obtenus pour ce type des données sont presenté dans l'annexe D1.3.

```{r include = FALSE}
# Clustering 
# Data creation
dataClustx = datai 
dataClustx_t1 = dataClustx %>% 
    filter(t == 1) %>% 
    dplyr::select(-t, -year)
dataClustx_t2 = dataClustx %>% 
    filter(t == 2) %>% 
    dplyr::select(-t, -year)
dataClustx_t3 = dataClustx %>% 
    filter(t == 3) %>% 
    dplyr::select(-t, -year)
dataClustx_t4 = dataClustx %>% 
    filter(t == 4) %>% 
    dplyr::select(-t, -year)
dataClustx_t5 = dataClustx %>% 
    filter(t == 5) %>% 
    dplyr::select(-t, -year)
# Joining data
dataCx = inner_join(dataClustx_t1, dataClustx_t2, 
    by = "ndep", suffix = c("", ".t2")) 
dataCx = inner_join(dataCx, dataClustx_t3, 
    by = "ndep", suffix = c("", ".t3")) 
dataCx = inner_join(dataCx, dataClustx_t4, 
    by = "ndep", suffix = c("", ".t4")) 
dataCx = inner_join(dataCx, dataClustx_t5, 
    by = "ndep", suffix = c("", ".t5")) 
# Analysis for clustering
wss3 = (nrow(dataCx[,-1])-1)*sum(apply(dataCx[,-1], 2, var))
for (i in 2:15) {
    wss3[i] = sum(kmeans(iter.max = 500, dataCx[,-1], centers = i)$withinss)
}
```

```{r include = FALSE}
# Grouping
fit3 = kmeans(iter.max = 100, dataC[,-6], 3)
# require(FactoMineR)
nclef3 = data.frame(ndep = as.factor(dataC$ndep), clust = fit3$cluster)
dataWZ = left_join(dataWi, nclef3, by = "ndep")
clusters3 = cbind(fit3$centers, fit3$size, k <- c(1:3)) %>%
    as.data.frame()
```

#### Comparaison des differentes méthodes

Afin de pouvoir comparer des valeurs differents de WSS (*within summ of squares*) nous allons visualiser la valeur dun indice : 

\begin{equation*}
    WSS^{'} = \frac{WSS}{min(WSS)}
\end{equation*}

Ce qui nous permettra d'évaluer les écarts rélatives du WSS de sa valeur minimale (pour nombre des clusters égal à 15).
Le graphique suivant démontre l'évaluation des valeurs de $WSS^{'}$ pour les trois cas differents de la définition des clusters :

\FloatBarrier

```{r echo = FALSE, results = "asis"}
# Graphique
plot(1:15, wss1/wss1[15], 
    type = "l", col = "red", 
    xlab = "Nomber de clusters",
    ylab = "WSS'") # 3, 4, 5
points(1:15, wss1/wss1[15], col = "red")
lines(1:15, wss2/wss2[15],
    col = "blue")
points(1:15, wss2/wss2[15], col = "blue")
lines(1:15, wss3/wss3[15],
    col = "green4")
points(1:15, wss3/wss3[15], col = "green4")
# Annotation
legend(x = "topright", 
    legend = c("Between", "Within", "Between et Within"),
    col = c("red", "blue", "green4"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

Nous pouvons observer que pour la transformation *within* nous observons la convergence la plus vite vers la valeure minimale de WSS. 
Les deux autres approches au traitement et transformation des données offrent une vitesse de convergence plus elevé, avec des valeurs rélatives initiales également plus significatives. 

Nous remarquons également que les valeurs optimales du nombre des clusters dans les trois cas sont à peu près identiques (autours de 3 et 5), avec la meilleure approximation absolute est atteint pour les huit cluster et reste rélativement inchangé après.

### M3.1 : Le cadre en absence des intéraction avec la demande 

Nous commençons par la comparaison des résultats obtenus pour les differents clusters avec les modèles de type OLS et IV-OLS.
C'est-à-dire, sous l'hypothèse de l'abcense des intérferences entre l'offre et la demande.

Nous n'evaluons pas le système en introduisant les variables de grouppe (dummy variables) car cela risque de biaiser les résultats à cause d'une taille des grouppes differente. 
Afin d'éviter ce biais nous évaluons les modèles par cluster.

Le tableau suivant regrouppe les 6 modèles éstimés (3 clusters avec 2 modèles par cluster, le nombre du cluster étant affiché après *c* dans le tableau) :

```{r include = FALSE}
# Data transformation
dataWZ = dataWZ %>% 
    mutate(ipi1 = ipi*as.numeric(clust == 1),
        ipi2 = ipi*as.numeric(clust == 2),
        ipi3 = ipi*as.numeric(clust == 3),
        ri1 = ri*as.numeric(clust == 1),
        ri2 = ri*as.numeric(clust == 2),
        ri3 = ri*as.numeric(clust == 3),
        si1 = si*as.numeric(clust == 1),
        si2 = si*as.numeric(clust == 2),
        si3 = si*as.numeric(clust == 3),
        iki1 = iki*as.numeric(clust == 1),
        iki2 = iki*as.numeric(clust == 2),
        iki3 = iki*as.numeric(clust == 3))
```

```{r include = FALSE}
# Equations
eqofferz = qi ~ 0 + ipi + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
instz = ~ ri1 + ri2 + ri3 + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
```

```{r include = FALSE}
# OLS 1
olsx1 = lm(eqoffer, 
    data = dataWZ[dataWZ$clust == 1,])
# IV-OLS 1
ivolsx1 = ivreg(eqoffer, 
    inst, 
    data = dataWZ[dataWZ$clust == 1,])
# OLS 2
olsx2 = lm(eqoffer, 
    data = dataWZ[dataWZ$clust == 2,])
# IV-OLS 2
ivolsx2 = ivreg(eqoffer, 
    inst, 
    data = dataWZ[dataWZ$clust == 2,])
# OLS 3
olsx3 = lm(eqoffer, 
    data = dataWZ[dataWZ$clust == 3,])
# IV-OLS 3
ivolsx3 = ivreg(eqoffer, 
    inst, 
    data = dataWZ[dataWZ$clust == 3,])
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(olsx1, ivolsx1,
        olsx2, ivolsx2,
        olsx3, ivolsx3),
    custom.model.names = c("OLS c1", "IV-OLS c1", 
        "OLS c2", "IV-OLS c2", 
        "OLS c3", "IV-OLS c3"),
    custom.coef.names = c("IP", "Surface", "I pésticides"),
    label = "table : ols et ivols clusters",
    caption = "Modèles économétriques, variable dépendante - la quantité du vin vendu (en log)")
```

\FloatBarrier

Nous observons que un cluster réssort d'une façon abnormale ayant des valeurs d'une magnitude excessive (c'est le département numéro 57 où l'indice a une variation intra-annuelle abnormale, on peut le considérer comme un outlier et ne pas le commenter).
En ce qui concerne les deux autres clusters, nous observons qu'un entre eux comprend les départements se spécialisant dans la production des vins simples (avec des effets des prix, de surface et d'utilisation des pésticides accentuté). 
L'autre regroupe des département qui montrent des effets moins réssortissants et evidents.

Les diagnostiques détaillés sont présentes dans l'annexe D2, où tous les tests principaux sont présents. 
Les tests sur la validité des éstimateurs IV sont les plus interessants et se trouvent dans l'annexe D2.3, ou nous observons que les estimations par les variables instrumentale n'est pas toujours valide dans notre cas. 
On ne peut pas rejeter l'hypothèse des faibles instruments seulement pour un des clusters, et le test de Wu-Haussman donne des résultats négatives pour tous les clusters, nous indiquant que le modèle OLS est préferable. 
Finalement, les résidus sont toujours non-normaux, bien que les résults du test sont les méilleurs dans l'ensemble (annexe D2.2).

### M3.2 : Le cadre d'interference avec la demande

Dans cette partie nous utilisons l'approche identique à celui qu'on a déjà implementé dans la partie M2. 
Nous supposons, que le marché fonctionne en presence des liens entre l'offre et la demande.
Les résidus des deux équations dans ce cas sont correlés entre eux.

```{r include = FALSE}
# Equations
eqdemandz = qi ~ 0 + ipi +
    ri1 + ri2 + ri3 
eqofferz = qi ~ 0 + ipi + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
instz = ~ ri1 + ri2 + ri3 + 
    si1 + si2 + si3 +
    iki1 + iki2 + iki3
systemz = list(Demande = eqdemandz, Offre = eqofferz)
```

```{r include = FALSE}
# Equations 
# SUR 1
surx1 = systemfit(system, 
    data = dataWZ[dataWZ$clust == 1,], 
    method = "SUR")
# 3SLS 1
sls3x1 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 1,], 
    method = "3SLS")
# FIML (iterated 3SLS) 1
fimlx1 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 1,], 
    method = "3SLS", maxit = 1000)
# SUR 2
surx2 = systemfit(system, 
    data = dataWZ[dataWZ$clust == 2,], 
    method = "SUR")
# 3SLS 2
sls3x2 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 2,], 
    method = "3SLS")
# FIML (iterated 3SLS) 2
fimlx2 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 2,], 
    method = "3SLS", maxit = 1000)
# SUR 3
surx3 = systemfit(system, 
    data = dataWZ[dataWZ$clust == 3,], 
    method = "SUR")
# 3SLS 3
sls3x3 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 3,], 
    method = "3SLS")
# FIML (iterated 3SLS) 3
fimlx3 = systemfit(system, 
    inst = inst,
    data = dataWZ[dataWZ$clust == 3,], 
    method = "3SLS", maxit = 1000)
```

Identiquement à la section précedente nous régrouppons les résultats d'estimation pour les 6 modèles (2 modèles par 3 clusters) sous la forme d'un tableau.

\FloatBarrier

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(surx1, sls3x1, 
        surx2, sls3x2, 
        surx3, sls3x3),
    custom.model.names = c("SUR c1", "3SLS c1",
        "SUR c2", "3SLS c2", 
        "SUR c3", "3SLS c3"),
    custom.coef.names = c("D : IP", "D : Revenu", 
        "O : IP", "O : Surface", "O : I pésticides"),
    label = "table : sur et 3sls clusters",
    caption = "Modèles économétriques, variable dépendante - la quantité du vin vendu (en log)")
```

\FloatBarrier

Nous observons que les effets des pésticides sur la quantité marchande du vin sont négligeables pour tous les clusters pour tous les modèles. 
La validité de ces modèles laisse à désirer.
D'abord, pour les modèles supposant l'endogénéité des prix dans notre modèle nous avons des instruments trop faibles, qui resultenet dans des modèles non-efficients.
De plus, l'introduction de l'hypothèse des liens entre les deux cotés du marché (introduction de la correlation entre les résidus) n'ameillore pas l'explicativité des modèles.

### Avis sur l'utilisation des clusters 

En genéral les clusters n'ameilleurent pas les résumtats des éstimations. 
Nous avons réussi à identifier un département trop different du reste dans sa nature, mais en total cette méthode n'a abouti à rien. 

De plus, nous rétirons de ces tentatives d'ammeilloration de notre modèle une evidence qu'il existent des département qui sont plus incliné à la production du vin de table que le reste, ce qui est tout à fait logique. 

# 9. Conclusion

```{r eval = FALSE, include = FALSE}
###################################################
###################  Conclusion  ##################
###################################################
```

Nous avons étudié et comparé plusieurs modèles distincts qui visent à apprécier les effets d'utilisation des pesticides sur l'offre de vin de table. 
Nous constatons, que parmi tout ces modèles, le meilleur estimateur des effets moyens par département est obtenu à travers un simple modèle OLS en absence d'effets d'interaction avec la demande de vin de table ou d'éndogénéité des prix. 
Ce fait est soutenu par les hypothèses théoriques sur le fonctionnement du marché des vins simples disponibles dans la littérature. 
Les agriculteurs proposant du vin simples sont dans la plupart des cas preneurs des prix offerts par les distributeurs, ce qui explique l'exogénéité des prix.
Le même fait explique l'absence des interactions entre l'offre et la demande, car les grands enseignes achetes le vin simple sous conditions *take or leave* (ce qui n'est pas vrai pour les autres types du vin).

L'analyse des données clusterisées permet d'observer un degré d'hétérogénéité relativement faible entre les départements. De plus, les effets d'utilisation des pesticides sur l'offre de vin ne sont clairement identifiables que pour un groupe spécifique d'entités étudiées.

Les résultats obtenus dans cette étude confirment des résultats obtenus par d'autres chercheurs, ainsi que les suppositions théoriques sur le rôle des pesticides dans le commerce du vin. 
Plus precisement, les pesticides sont utilisés par les viticulteurs pour minimiser les pertes causées par les maladies, les fongicides... etc.
Nous captons ce phénomène en estimant le modèle d'équilibre du marché du vin simple. 

Nous devons également souligner que le modèle presenté dans ce travail est loin de frôler la perfection absolue. 
Plusieurs problèmes restent non-traité ou non-résolus. Parmi ces problèmes nous pouvons citer: un faible nombre d'observations sur la dimention temporelle, la présence d'heteroscedasticité dans les résidus, la non-normalité des résidus, des variables omises, dess instruments faibles, etc.
Toutefois, nous avons reussi à capter la tendance principale dans le comportement de l'offre face à l'utilisation des pesticides par les agriculteurs. Il peut donc s'avérer interessant d'étudier ces aspects et de traiter ces problèmes revelés dans de futures études.

Pour de futures recherches, nous conseillerons d'étudier directement l'impact des pesticides sur la production et non sur l'équilibre du marché parce que, comme nous avons pu le constater dans nos résultats, la modélisation du marché via des équations simultanées ne nous permet pas d'améliorer significativement nos estimateurs. Ceci constitue un point important, étant donné le faible nombre de variables explicatives sélectionnées et les défauts potentiels dans la spécification de notre modèle, dans notre étude ces modèles se prouvent d'être innefficaces et ne donne pas des résultats fiables.

\newpage

# Annexes 

```{r eval = FALSE, include = FALSE}
################################################
###################  Annexes  ##################
################################################
```

## A Les statistiques descriptives 

### A1 Les moyennes par département 

\FloatBarrier

```{r echo = FALSE, fig.height = 4, results = "asis", fig.cap = "Les valeurs moyennes par département"}
# Plot
p1 = spplot(formes, "ipi", 
    col.regions = colorRampPalette(c('grey96', 'blue'))(30),  
    main = list(label = "Index prix du vin par département", cex = 0.8))
p2 = spplot(formes, "iki", 
    col.regions = colorRampPalette(c('grey96', 'green4'))(30),  
    main = list(label = "Index pesticides par département", cex = 0.8))
p3 = spplot(formes, "si", 
    col.regions = colorRampPalette(c('grey96', 'red'))(30),  
    main = list(label = "Surface qultivé par département", cex = 0.8))
p4 = spplot(formes, "ri", 
    col.regions = colorRampPalette(c('grey96', 'orange'))(30),  
    main = list(label = "Revenus par département", cex = 0.8))
return(grid.arrange(p1, p2, p3, p4, nrow = 2))
```

\FloatBarrier

\newpage

### A2 L'étude des interdépendances

La premier de cet annexe combrend les résultats pour les données telles-quelles, le deuxieme par contre integre les résultats pour les données sous la trasformation *within*.

####  A2.1 Information complète 

\FloatBarrier

```{r echo = FALSE, fig.height = 4, fig.cap = "L'étude bivarié"}
p1 = datai %>% 
    ggplot(aes(y = qi, x = ipi, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ IP") +
    ylab("Quantité du vin") + xlab("Index du prix") +
    pres_theme + xlim(0, 10)
p2 = datai %>% 
    ggplot(aes(y = qi, x = iki, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ IK") +
    ylab("Quantité du vin") + xlab("Index des pésticides") +
    pres_theme + xlim(0, 4)
# Probably it is better to do it by variable
p3 = datai %>% 
    ggplot(aes(y = qi, x = si, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ S") +
    ylab("Quantité du vin") + xlab("Surface qultivé") +
    pres_theme
p4 = datai %>% 
    ggplot(aes(y = qi, x = ri, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    # ggtitle("Q ~ R") +
    ylab("Quantité du vin") + xlab("Revenus") +
    pres_theme
return(grid.arrange(p1, p2, p3, p4, nrow = 2))
```

\FloatBarrier

```{r include = FALSE}
correlation = cor(datap)
colnames(correlation) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
rownames(correlation) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "I pésticides", "Temps")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
print(xtable(round(correlation, 4), 
    caption = "La correlation complete",
    align = "l|rrrrrr"), caption.placement = "bottom")
```

\FloatBarrier

\newpage

#### A2.2 Transformation *within*

Les rélations entre les variables mieux ressortent pour les données transformées. 
Ce sont les données que nous intégrons dans nos modèles économétriques.

\FloatBarrier

```{r echo = FALSE, fig.height = 4, fig.cap = "Rélations bivariés dans le cas de transformation within"}
p1 = dataWi %>% 
    ggplot(aes(y = qi, x = ipi, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, ipi, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ IP") +
    ylab("Quantité du vin") + xlab("Index du prix") +
    pres_theme + xlim(-4, 4)
p2 = dataWi %>% 
    ggplot(aes(y = qi, x = iki, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, iki, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ IK") +
    ylab("Quantité du vin") + xlab("Index des pésticides") +
    pres_theme + xlim(-1, 4)
# Probably it is better to do it by variable
p3 = dataWi %>% 
    ggplot(aes(y = qi, x = si, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, si, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ S") +
    ylab("Quantité du vin") + xlab("Surface qultivé") +
    pres_theme
p4 = dataWi %>% 
    ggplot(aes(y = qi, x = ri, col = as.factor(ndep))) +
    geom_point(size = 0.5) + 
    geom_smooth(method = "lm", se = F, size = 0.25) +
    geom_smooth(aes(qi, ri, col = "black"), method = "loess", size = 0.4) +
    # ggtitle("Q ~ R") +
    ylab("Quantité du vin") + xlab("Revenus") +
    pres_theme + xlim(-0.05, 0.05) #### ERRORS!!!!
return(grid.arrange(p1, p2, p3, p4, nrow = 2))
```

\FloatBarrier

```{r include = FALSE}
correlationW = cor(dataW)
dataW$ndep = index(datap)$ndep
colnames(correlationW) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "Index pésticides", "Temps")
rownames(correlationW) = c("Quantité du vin", "IP", 
        "Surface", "Revenus", 
        "I pésticides", "Temps")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
print(xtable(round(correlationW, 4), 
    caption = "La correlation within",
    align = "l|rrrrrr"), caption.placement = "bottom")
```

\FloatBarrier

\newpage

## B Analyse des résultats du cadre M1

### B1 Le compoertement des résidus  

```{r include = FALSE}
# Correlation
cordata = dataW %>% 
    mutate(u1 = ols$res,
        u2 = ivols$res)
cormat = cor(cordata[,-c(6, 7)])[1:5, 6:7]
colnames(cormat) = c("OLS", "IV-OLS")
rownames(cormat) = c("Vin", "IP", 
        "Surface", "Revenus", 
        "Pesticides")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
print(xtable(round(cormat, 4), 
    caption = "Correlation des résidus",
    align = "l|rr",
    floating = T), caption.placement = "bottom")
```

\FloatBarrier

\FloatBarrier

```{r echo = FALSE, fig.cap = "Le comportement des résidus"}
# Visualisation des résidus
par(mfrow = c(1,2), cex = 0.5)
plot(y = as.numeric(ols$res), x = as.numeric(ols$fit),
    col = "blue", 
    main = "Les résidus contre la variable prédite", 
    ylab = "Residuals", xlab = "Fitted")
points(y = as.numeric(ivols$res), x = as.numeric(ivols$fit),
    col = "red", pch = 17)
legend(x = "topright", legend = c("OLS", "IV-OLS"),
    col = c("blue", "red"), xpd = NA,
    cex = 1, lwd = 3)
# Representation graphique des résidus
plot(density(ols$res), col = "blue", 
    main = "Les PDF des résidus", xlab = "Residuals")
lines(density(ivols$res), col = "red")
legend(x = "topright", legend = c("OLS", "IV-OLS"),
    col = c("blue", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

### B2 L'autocorrelation

```{r include = FALSE}
# Panel Durbin-Watson test
cordataDW = cordata %>% 
    group_by(ndep) %>%
    mutate(u1_diff = u1 - dplyr::lag(u1),
        u2_diff = u2 - dplyr::lag(u2)) %>%
    ungroup() %>%
    dplyr::select(contains("u")) %>%
    mutate_all(function(x) replace_na(x, 0)) %>%
    summarise_all(function(x) sum(x^2))
pDW = data.frame(ncol = 2, nrow = 1)
pDW[1,1] = cordataDW[1,1]/cordataDW[1,3]
pDW[1,2] = cordataDW[1,2]/cordataDW[1,4]
colnames(pDW) = c("OLS", "IV-OLS")
rownames(pDW) = c("Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(pDW, 
    header = FALSE,
    title = "Les statistiques test de Durbin-Watson, t-stat",
    summary = FALSE)
```

\FloatBarrier

### B3 Test de l'hétéroskedacité

```{r include = FALSE}
BartT = data.frame(ncol = 2, nrow = 1)
BartT[1,1] = ols_test_bartlett(cordata, u1, 
    group_var = ndep)$pval
BartT[1,2] = ols_test_bartlett(cordata, u2, 
    group_var = ndep)$pval
colnames(BartT) = c("OLS", "IV-OLS")
rownames(BartT) = c("Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(BartT,
    header = FALSE,
    summary = FALSE,
    title = "Les résultat du test de Bartlett sur l'heteroscedacité, p-valeur")
```

\FloatBarrier

### B4 La normalité des résidus 

\FloatBarrier

```{r include = FALSE}
# Shapiro-Wilk test
ShapT = data.frame(nrow = 1, ncol = 2)
ShapT[1,1] = shapiro.test(ols$res)$p.val
ShapT[1,2] = shapiro.test(ivols$res)$p.val
colnames(ShapT) = c("OLS", "IV-OLS")
rownames(ShapT) = c("Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk test de normalité des résidus, p-valeur")
```

\FloatBarrier

### B5 Diagnostics IV-OLS 

```{r include = FALSE}
# IV-OLS diagnostics
ivchek = summary(ivols, diagnostics = TRUE)$diag
ivchek = ivchek[-3,]
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ivchek,
    header = FALSE,
    summary = FALSE,
    title = "Diagnostiques d'estimateur IV")
```

\FloatBarrier

\newpage 

## C Analyse des résultats M2

### C1 Comparaison des modèles 2SLS, 3SLS et i3SLS

\FloatBarrier

```{r echo = FALSE, results = "asis"}
texreg(float.pos = "!htbp", 
    list(sur, sls2, sls3, fiml),
    custom.model.names = c("SUR", "2SLS", "3SLS", "i3SLS"),
    custom.coef.names = c("D : IP", "D : Revenu", 
        "O : IP", "O : Surface", "O : I pésticides"),
    label = "table : sur, 2sls, 3sls and fiml",
    caption = "Modèles économétriques, variable dépendante - la quantité du vin vendu (en log)")
```

\FloatBarrier

\newpage

### C2 Indépendance des résidus  

```{r include = FALSE}
resdata3 = dataW %>% 
    mutate(u1 = sur$eq[[1]]$res,
        u2 = sur$eq[[2]]$res,
        u3 = sls2$eq[[1]]$res,
        u4 = sls2$eq[[2]]$res,
        u5 = sls3$eq[[1]]$res,
        u6 = sls3$eq[[2]]$res,
        u7 = fiml$eq[[1]]$res,
        u8 = fiml$eq[[2]]$res)
```

```{r include = FALSE}
cormat = cor(resdata3[,-c(6,7)])
cormat = cormat[1:5, 6:13]
colnames(cormat) = c("SUR D", "SUR O",
        "2SLS D", "2SLS O", 
        "3SLS D", "3SLS O",
        "i3SLS D", "i3SLS O")
rownames(cormat) = c("Vin", "IP", 
        "Surface", "Revenus", 
        "Pesticides")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
print(xtable(round(cormat, 4), 
    caption = "Correlation des résidus",
    align = "l|rrrrrrrr"), caption.placement = "bottom")
```

\FloatBarrier

\FloatBarrier

```{r echo = FALSE, fig.cap = "Les résidus contre la variable prédite"}
par(mfrow = c(1,2), cex = 0.5)
plot(y = sls2$eq[[1]]$res, x = sls2$eq[[1]]$fit,
    col = "blue", 
    main = "Demande", 
    ylab = "Residuals", xlab = "Fitted")
points(y = sur$eq[[1]]$res, x = sur$eq[[1]]$fit,
    col = "green4", pch = 17)
points(y = sls3$eq[[1]]$res, x = sls3$eq[[1]]$fit,
    col = "red", pch = 14)
plot(y = sls2$eq[[2]]$res, x = sls2$eq[[2]]$fit,
    col = "blue", 
    main = "Offre", 
    ylab = "Residuals", xlab = "Fitted")
points(y = sur$eq[[2]]$res, x = sur$eq[[2]]$fit,
    col = "green4", pch = 17)
points(y = sls3$eq[[2]]$res, x = sls3$eq[[2]]$fit,
    col = "red", pch = 14)
par(xpd = NA)
legend(x = "topright", legend = c("2SLS", "i3SLS", "3SLS"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

\FloatBarrier

```{r echo = FALSE, fig.cap = "Les résidus et les prédictions, le cas de SUR"}
par(mfrow = c(1,2), cex = 0.5)
plot(y = sur$eq[[1]]$res, x = as.numeric(resdata3$qi),
    col = "red", pch = 17, 
    main = "Demande", 
    ylab = "Fitted - résidus", xlab = "Real", xlim = c(-2, 2), ylim = c(-2, 1))
points(y = sur$eq[[1]]$fit, x = resdata3$qi, 
    col = "blue", pch = 17)
lines(y = sur$eq[[1]]$fit + sur$eq[[1]]$res, x = resdata3$qi,
    col = "black")
legend(x = "bottomleft", legend = c("Résidus", "Fitted", "Real"),
    col = c("red", "blue", "black"), xpd = NA,
    cex = 1, lwd = 3)
plot(y = sur$eq[[2]]$fit, x = as.numeric(resdata3$qi), 
    col = "blue", pch = 17, 
    main = "Offre", 
    ylab = "Fitted - résidus", xlab = "Real", xlim = c(-2, 2), ylim = c(-2, 1))
points(y = sur$eq[[2]]$res, x = resdata3$qi,
    col = "red", pch = 14)
lines(y = sur$eq[[2]]$fit + sur$eq[[2]]$res, x = resdata3$qi,
    col = "black")
```

\FloatBarrier

\newpage

### C3 L'autocorrelation 

```{r include = FALSE}
# Panel Durbin-Watson test
# Create dataframe
resdataDW = resdata3 %>% 
    group_by(ndep) %>%
    mutate(u1_diff = u1 - dplyr::lag(u1),
        u2_diff = u2 - dplyr::lag(u2),
        u3_diff = u3 - dplyr::lag(u3),
        u4_diff = u4 - dplyr::lag(u4),
        u5_diff = u5 - dplyr::lag(u5),
        u6_diff = u6 - dplyr::lag(u6),
        u7_diff = u7 - dplyr::lag(u7),
        u8_diff = u8 - dplyr::lag(u8)) %>%
    ungroup() %>%
    dplyr::select(contains("u")) %>%
    mutate_all(function(x) replace_na(x, 0)) %>%
    summarise_all(function(x) sum(x^2))
# Calculate test statistics
pDW = data.frame(ncol = 4, nrow = 2)
pDW[1,1] = resdataDW[1,1]/resdataDW[1,9]
pDW[2,1] = resdataDW[1,2]/resdataDW[1,10]
pDW[1,2] = resdataDW[1,3]/resdataDW[1,11]
pDW[2,2] = resdataDW[1,4]/resdataDW[1,12]
pDW[1,3] = resdataDW[1,5]/resdataDW[1,13]
pDW[2,3] = resdataDW[1,6]/resdataDW[1,14]
pDW[1,4] = resdataDW[1,7]/resdataDW[1,15]
pDW[2,4] = resdataDW[1,8]/resdataDW[1,16]
# Rename
colnames(pDW) = c("SUR", "2SLS", "3SLS", "i3SLS")
rownames(pDW) = c("Equation de demande", "Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(pDW,
    header = FALSE,
    title = "Les resultats du test de Durbin-Watson, t-stat",
    summary = FALSE)
```

\FloatBarrier

### C4 Test de l'hétéroscedasticité

```{r include = FALSE}
BartT = data.frame(ncol = 4, nrow = 2)
BartT[1,1] = ols_test_bartlett(resdata3, u1, group_var = ndep)$pval
BartT[2,1] = ols_test_bartlett(resdata3, u2, group_var = ndep)$pval
BartT[1,2] = ols_test_bartlett(resdata3, u3, group_var = ndep)$pval
BartT[2,2] = ols_test_bartlett(resdata3, u4, group_var = ndep)$pval
BartT[1,3] = ols_test_bartlett(resdata3, u5, group_var = ndep)$pval
BartT[2,3] = ols_test_bartlett(resdata3, u6, group_var = ndep)$pval
BartT[1,4] = ols_test_bartlett(resdata3, u7, group_var = ndep)$pval
BartT[2,4] = ols_test_bartlett(resdata3, u8, group_var = ndep)$pval
colnames(BartT) = c("SUR", "2SLS", "3SLS", "i3SLS")
rownames(BartT) = c("Equation de demande", "Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(BartT,
    header = FALSE,
    summary = FALSE,
    title = "Test de Bartlett sur l'heterockedacité, p-valeur")
```

\FloatBarrier

### C5 La normalité des résidus 

\FloatBarrier

```{r include = FALSE}
ShapT = data.frame(nrow = 2, ncol = 4)
ShapT[1,1] = shapiro.test(sur$eq[[1]]$res)$p.val
ShapT[2,1] = shapiro.test(sur$eq[[2]]$res)$p.val
ShapT[1,2] = shapiro.test(sls2$eq[[1]]$res)$p.val
ShapT[2,2] = shapiro.test(sls2$eq[[2]]$res)$p.val
ShapT[1,3] = shapiro.test(sls3$eq[[1]]$res)$p.val
ShapT[2,3] = shapiro.test(sls3$eq[[2]]$res)$p.val
ShapT[1,4] = shapiro.test(fiml$eq[[1]]$res)$p.val
ShapT[2,4] = shapiro.test(fiml$eq[[2]]$res)$p.val
colnames(ShapT) = c("SUR", "2SLS", "3SLS", "i3SLS")
rownames(ShapT) = c("Equation de demande", "Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk test de normalité, p-valeur")
```

\FloatBarrier

\FloatBarrier

```{r echo = FALSE, fig.height = 4, fig.cap = "Les PDF des résidus"}
par(mfrow = c(1,2), cex = 0.5)
plot(density(sls2$eq[[1]]$res), col = "blue", 
    main = "Demande", xlab = "Residuals")
lines(density(sur$eq[[1]]$res), col = "green4")
lines(density(sls3$eq[[1]]$res), col = "red")
plot(density(sls3$eq[[2]]$res), col = "red", 
    main = "Offre", xlab = "Residuals")
lines(density(sur$eq[[2]]$res), col = "green4")
lines(density(sls2$eq[[2]]$res), col = "blue")
legend(x = "topright", legend = c("2SLS", "i3SLS", "3SLS"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

### C6 Comparaison des modèles  

\FloatBarrier

```{r include = FALSE}
h1 = hausman.systemfit(sls3, sls2) # p = 1, 3SLS inconsistent
# 2SLS estimator is consistent
h2 = hausman.systemfit(sls3, sur)
res = data.frame(Test = c("3SLS contre 2SLS", "3SLS contre SUR"),
    Resultats = c(h1$p.val, h2$p.val))
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(res, 
    title = "Hausman 3SLS consistency test, p-valeur",
    summary = F, 
    header = F)
``` 

\FloatBarrier

```{r include = FALSE}
# - Linear test :
# What should be tested ???
# linearHypothesis(sls2, 
```
\FloatBarrier

```{r echo = FALSE, results = "asis"}
lr = lrtest(sur, sls2, sls3, fiml)
print(xtable(round(lr, 4), 
    caption = "ML test de spécification",
    align = "c|ccccc"), caption.placement = "bottom")
```

\FloatBarrier

\newpage 

## D Clusterisation 

### D1 Méthodes de clusterisation

#### D1.1 Les centres pour les données *between* 

Les groupes sont définies par des caractéristiques suivantes :

\FloatBarrier

```{r echo = FALSE, results = "asis"}
clusters1 = cbind(fit1$centers, fit1$size)
names(clusters1) = c("Groupe", "Quantité", "IP", 
    "Surface", "Revenus", "Index pesticides", "n ")
stargazer(clusters1, 
    title = "Les centres des clusters",
    summary = F, 
    header = F)
```

\FloatBarrier

#### D1.2 Les centres pour les données *within*  

Les groupes sont définies par des caractéristiques suivantes :

```{r include = FALSE}
names(clusters2)[(ncol(clusters2)-1):ncol(clusters2)] = c("n", "k")
c1 = clusters2 %>%
    dplyr::select(qi, ipi, si, ri, iki, n, k) %>%
    mutate(t = 1)
c2 = clusters2 %>%
    dplyr::select(ends_with("t2"), n, k) %>%
    mutate(t = 2)
names(c2)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c3 = clusters2 %>%
    dplyr::select(ends_with("t3"), n, k) %>%
    mutate(t = 3)
names(c3)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c4 = clusters2 %>%
    dplyr::select(ends_with("t4"), n, k) %>%
    mutate(t = 4)
names(c4)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c5 = clusters2 %>%
    dplyr::select(ends_with("t5"), n, k) %>%
    mutate(t = 5)
names(c5)[1:5] = c("qi", "ipi", "si", "ri", "iki")
centers2 = rbind(c1, c2, c3, c4, c5) %>% 
    group_by(k) %>% 
    arrange(t, .by_group = T)
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
# Print results
stargazer(round(centers2, 6), 
    title = "Les centres des clusters",
    summary = F, 
    header = F)
```

\FloatBarrier

\newpage

#### D1.3 Les centres pour l'information complete 

Les groupes sont définit par les caractéristiques suivantes :

```{r include = FALSE}
names(clusters3)[(ncol(clusters3)-1):ncol(clusters3)] = c("n", "k")
c1 = clusters3 %>%
    dplyr::select(qi, ipi, si, ri, iki, n, k) %>%
    mutate(t = 1)
c2 = clusters3 %>%
    dplyr::select(ends_with("t2"), n, k) %>%
    mutate(t = 2)
names(c2)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c3 = clusters3 %>%
    dplyr::select(ends_with("t3"), n, k) %>%
    mutate(t = 3)
names(c3)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c4 = clusters3 %>%
    dplyr::select(ends_with("t4"), n, k) %>%
    mutate(t = 4)
names(c4)[1:5] = c("qi", "ipi", "si", "ri", "iki")
c5 = clusters3 %>%
    dplyr::select(ends_with("t5"), n, k) %>%
    mutate(t = 5)
names(c5)[1:5] = c("qi", "ipi", "si", "ri", "iki")
centers3 = rbind(c1, c2, c3, c4, c5) %>% 
    group_by(k) %>% 
    arrange(t, .by_group = T)
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
# Print 
stargazer(round(centers3, 6), 
    title = "Les centres des clusters",
    summary = F, 
    header = F)
```

\FloatBarrier

\newpage

### D2 Les modèles en absence d' intéractions du marché

#### D2.1 Le comportement des résidus

```{r echo = FALSE, fig.cap = "Le comportement des résidus pour le modèle OLS"}
# Visualisation des résidus
par(mfrow = c(1,2), cex = 0.5)
plot(y = as.numeric(olsx1$res), x = as.numeric(olsx1$fit),
    col = "blue", 
    main = "Les résidus contre la variable prédite", 
    ylab = "Residuals", xlab = "Fitted")
points(y = as.numeric(olsx2$res), x = as.numeric(olsx2$fit),
    col = "green4", pch = 17)
points(y = as.numeric(olsx3$res), x = as.numeric(olsx3$fit),
    col = "red", pch = 14)
legend(x = "topright", legend = c("Cluster 1", "Cluster 2", "Cluster 3"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
# Representation graphique des résidus
plot(density(olsx1$res), col = "blue", 
    main = "Les PDF des résidus", xlab = "Residuals")
lines(density(olsx2$res), col = "green4")
lines(density(olsx3$res), col = "red")
legend(x = "topright", legend = c("Cluster 1", "Cluster 2", "Cluster 3"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

#### D2.2 La normalité des résidus 

\FloatBarrier

```{r include = FALSE}
# Shapiro-Wilk test
ShapT = data.frame(nrow = 1, ncol = 2)
ShapT[1,1] = shapiro.test(olsx1$res)$p.val
ShapT[1,2] = shapiro.test(ivolsx1$res)$p.val
ShapT[1,3] = shapiro.test(olsx2$res)$p.val
ShapT[1,4] = shapiro.test(ivolsx2$res)$p.val
ShapT[1,5] = shapiro.test(olsx3$res)$p.val
ShapT[1,6] = shapiro.test(ivolsx3$res)$p.val
colnames(ShapT) = c("OLS c1", "IV-OLS c1", 
        "OLS c2", "IV-OLS c2", 
        "OLS c3", "IV-OLS c3")
rownames(ShapT) = c("Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk test de normalité des résidus, p-valeur")
```

\FloatBarrier

\newpage

#### B2.3 Diagnostiques IV-OLS 

```{r include = FALSE}
# IV-OLS diagnostics
ivchek1 = summary(ivolsx1, diagnostics = TRUE)$diag
ivchek1 = ivchek1[-3,]
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ivchek1,
    header = FALSE,
    summary = FALSE,
    title = "Diagnostiques d'estimateur IV, cluster 1")
```

\FloatBarrier

```{r include = FALSE}
# IV-OLS diagnostics
ivchek2 = summary(ivolsx2, diagnostics = TRUE)$diag
ivchek2 = ivchek2[-3,]
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ivchek2,
    header = FALSE,
    summary = FALSE,
    title = "Diagnostiques d'estimateur IV, cluster 2")
```

\FloatBarrier

```{r include = FALSE}
# IV-OLS diagnostics
ivchek3 = summary(ivolsx3, diagnostics = TRUE)$diag
ivchek3 = ivchek3[-3,]
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ivchek3,
    header = FALSE,
    summary = FALSE,
    title = "Diagnostiques d'estimateur IV, cluster 3")
```

\FloatBarrier

\newpage 

### D3 Analyse des résultats M2

#### D3.1 Independance des résidus  

\FloatBarrier

```{r echo = FALSE, fig.cap = "Les résidus contre la variable prédite, le cadre SUR"}
par(mfrow = c(1,2), cex = 0.5)
plot(y = surx1$eq[[1]]$res, x = surx1$eq[[1]]$fit,
    col = "blue", 
    main = "Demande", 
    ylab = "Residuals", xlab = "Fitted")
points(y = surx2$eq[[1]]$res, x = surx2$eq[[1]]$fit,
    col = "green4", pch = 17)
points(y = surx3$eq[[1]]$res, x = surx3$eq[[1]]$fit,
    col = "red", pch = 14)
plot(y = surx1$eq[[2]]$res, x = surx1$eq[[2]]$fit,
    col = "blue", 
    main = "Offre", 
    ylab = "Residuals", xlab = "Fitted")
points(y = surx2$eq[[2]]$res, x = surx2$eq[[2]]$fit,
    col = "green4", pch = 17)
points(y = surx3$eq[[2]]$res, x = surx3$eq[[2]]$fit,
    col = "red", pch = 14)
par(xpd = NA)
legend(x = "topright", 
    legend = c("Cluster 1", "Cluster 2", "Cluster 3"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

\newpage

### D3.2 La normalité des résidus, le cadre de SUR

\FloatBarrier

```{r include = FALSE}
ShapT = data.frame(nrow = 2, ncol = 3)
ShapT[1,1] = shapiro.test(surx1$eq[[1]]$res)$p.val
ShapT[2,1] = shapiro.test(surx1$eq[[2]]$res)$p.val
ShapT[1,2] = shapiro.test(surx2$eq[[1]]$res)$p.val
ShapT[2,2] = shapiro.test(surx2$eq[[2]]$res)$p.val
ShapT[1,3] = shapiro.test(surx3$eq[[1]]$res)$p.val
ShapT[2,3] = shapiro.test(surx3$eq[[2]]$res)$p.val
colnames(ShapT) = c("Cluster 1", "Cluster 2", "Cluster 3")
rownames(ShapT) = c("Equation de demande", "Equation d'offre")
```

\FloatBarrier

```{r echo = FALSE, results = "asis"}
stargazer(ShapT,
    header = FALSE,
    summary = FALSE,
    title = "Shapiro-Wilk test de normalité, p-valeur")
```

\FloatBarrier

\FloatBarrier

```{r echo = FALSE, fig.height = 4, fig.cap = "Les PDF des résidus"}
par(mfrow = c(1,2), cex = 0.5)
plot(density(surx1$eq[[1]]$res), col = "blue", 
    main = "Demande", xlab = "Residuals")
lines(density(surx2$eq[[1]]$res), col = "green4")
lines(density(surx3$eq[[1]]$res), col = "red")
plot(density(surx3$eq[[2]]$res), col = "red", 
    main = "Offre", xlab = "Residuals")
lines(density(surx2$eq[[2]]$res), col = "green4")
lines(density(surx1$eq[[2]]$res), col = "blue")
legend(x = "topright", 
    legend = c("Cluster 1", "Cluster 2", "Cluster 3"),
    col = c("blue", "green4", "red"), xpd = NA,
    cex = 1, lwd = 3)
```

\FloatBarrier

\newpage

# References 

```{r eval = FALSE, include = FALSE}
#####################################################
###################   References   ##################
#####################################################
```
